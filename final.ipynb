{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openai\n",
    "import json, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dicts import RQ1_dict\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "#####################\n",
    "\"\"\" from tokens.key import github_key # import your key\n",
    "from tokens.key import openai_key # import your key \"\"\"\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "github_key = os.getenv('GITHUB_KEY')\n",
    "openai_key = os.getenv('OPENAI_KEY')\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_unimportant_spaces(code: str) -> str:\n",
    "    # Remove spaces and tabs around operators and punctuation\n",
    "    code = re.sub(r'\\s*([\\+\\-\\*/%=&\\|!<>;,\\(\\)\\{\\}\\[\\]])\\s*', r' \\1 ', code)\n",
    "\n",
    "    # Remove extra spaces and tabs at the beginning and end of each line\n",
    "    code = '\\n'.join(line.strip() for line in code.split('\\n'))\n",
    "\n",
    "    # Replace consecutive spaces with a single space\n",
    "    code = re.sub(r' +', ' ', code)\n",
    "\n",
    "    return code\n",
    "\n",
    "def parse_patch_no_lines(patch):\n",
    "    lines = []\n",
    "\n",
    "    for line in patch.splitlines():\n",
    "        if line.startswith('-'):\n",
    "            lines.append(line[1:])\n",
    "        elif line.startswith(' '):\n",
    "            lines.append(line[1:])\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def parse_patch(patch):\n",
    "    lines = []\n",
    "    old_line_number = None\n",
    "    new_line_number = None\n",
    "\n",
    "    for line in patch.splitlines():\n",
    "        if line.startswith('@@'):\n",
    "            old_line_number, new_line_number = map(int, re.findall(r'\\d+', line)[:2])\n",
    "        elif line.startswith('-'):\n",
    "            lines.append(f\"{old_line_number}: {line[1:]}\")\n",
    "            old_line_number += 1\n",
    "        elif line.startswith('+'):\n",
    "            new_line_number += 1\n",
    "        elif line.startswith(' '):\n",
    "            lines.append(f\"{old_line_number}: {line[1:]}\")\n",
    "            old_line_number += 1\n",
    "            new_line_number += 1\n",
    "\n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a software high performance engineering assistant with exceptional intelligence, your task is to analyze a given piece of code and identify any performance issues. Specifically, you are expected to classify any performance problems you detect into only  single one of the following categories: Inefficient coding for target micro-architecure, Missing parallelism, Parallelization overhead/inefficiency, Inefficient Concurrency control and synchronization, Unnecessary process communication, Inefficient algorithm /data-structure and their implementation, Inefficient memory management, I/O inefficiency, Unintentional Programming logic error, Inefficiency due to new compiler version, .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catagories = \"\"\n",
    "for i in RQ1_dict:\n",
    "    catagories += i + \", \"\n",
    "#print(catagories)\n",
    "\n",
    "system_promt = f\"As a software high performance engineering assistant with exceptional intelligence, your task is to analyze a given piece of code and identify any performance issues. Specifically, you are expected to classify any performance problems you detect into only  single one of the following categories: {catagories}.\"\n",
    "\n",
    "system_promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, as I am an AI language model, I am unable to provide you with specific code to analyze. However, I can provide you with general guidelines on how to identify performance issues in code. Some common areas to look for include:\n",
      "\n",
      "1. Inefficient coding for target micro-architecture: Check if the code is not optimized for the target hardware platform, causing it to run slowly. You can use performance profiling tools to gather detailed information about how the code is executing at a low level.\n",
      "\n",
      "2. Missing parallelism: Look for sections of code that are serial in nature and can be parallelized. This can significantly speed up the execution time by utilizing all available resources.\n",
      "\n",
      "3. Parallelization overhead/inefficiency: Ensure that the overhead associated with parallelization is not affecting overall performance. Some parallelization techniques can cause significant overhead, negating any performance gains achieved by parallelism.\n",
      "\n",
      "4. Inefficient concurrency control and synchronization: Be sure to properly manage concurrency control and synchronization in concurrent code to avoid contention and deadlocks.\n",
      "\n",
      "5. Unnecessary process communication: Check if excess communication between processes is causing a performance bottleneck. This can be done by profiling communication times and minimizing where possible.\n",
      "\n",
      "6. Inefficient algorithm/data-structure and their implementation: Check if the algorithm and data structure used are the most efficient for the problem at hand. Small changes in algorithm optimization can result in significant performance gains.\n",
      "\n",
      "7. Inefficient memory management: Watch out for situations where memory usage is inefficient, leading to excessive overhead related to memory allocation and deallocation.\n",
      "\n",
      "8. I/O inefficiency: Check if the I/O calls are causing a bottleneck in performance. Be sure to use asynchronous I/O where possible to minimize wait times.\n",
      "\n",
      "9. Unintentional Programming logic error: Identify any unintentional errors in programming logic and refactor code to optimize it.\n",
      "\n",
      "10. Inefficiency due to new compiler version: Check if a new version of the compiler is affecting performance. In some cases, the performance of compiled code can be affected by changes in the compiler.\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = openai_key\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": system_promt},\n",
    "      {\"role\": \"user\", \"content\": f\"insert code here\"} ,       \n",
    "    ],   \n",
    "  \n",
    ")\n",
    "print(response['choices'][0]['message'][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_links=  []\n",
    "with open (\"Data/RQ1/cuda_links.txt\",\"r\") as f:\n",
    "    for i in f :\n",
    "        #print(i.replace('\\n', ''))   \n",
    "        git_links.append(i.replace('\\n', ''))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://github.com/ginkgo-project/ginkgo/commit/154aafbd57e93e4ede30b1566d2bf03e7c1b096e': {'sha': '154aafbd57e93e4ede30b1566d2bf03e7c1b096e',\n",
       "  'node_id': 'MDY6Q29tbWl0MTE3MTIyNTEwOjE1NGFhZmJkNTdlOTNlNGVkZTMwYjE1NjZkMmJmMDNlN2MxYjA5NmU=',\n",
       "  'commit': {'author': {'name': 'Terry Cojean',\n",
       "    'email': 'terry.cojean@kit.edu',\n",
       "    'date': '2018-12-05T15:20:32Z'},\n",
       "   'committer': {'name': 'Terry Cojean',\n",
       "    'email': 'terry.cojean@kit.edu',\n",
       "    'date': '2018-12-05T16:15:03Z'},\n",
       "   'message': 'Stopping criterion: improve the performance one last time by using a kernel for the boolean initialization instead of a synchronous copy.',\n",
       "   'tree': {'sha': '9c57d2e86d1f3a043de0f4e87b588f4e2897c1f1',\n",
       "    'url': 'https://api.github.com/repos/ginkgo-project/ginkgo/git/trees/9c57d2e86d1f3a043de0f4e87b588f4e2897c1f1'},\n",
       "   'url': 'https://api.github.com/repos/ginkgo-project/ginkgo/git/commits/154aafbd57e93e4ede30b1566d2bf03e7c1b096e',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/ginkgo-project/ginkgo/commits/154aafbd57e93e4ede30b1566d2bf03e7c1b096e',\n",
       "  'html_url': 'https://github.com/ginkgo-project/ginkgo/commit/154aafbd57e93e4ede30b1566d2bf03e7c1b096e',\n",
       "  'comments_url': 'https://api.github.com/repos/ginkgo-project/ginkgo/commits/154aafbd57e93e4ede30b1566d2bf03e7c1b096e/comments',\n",
       "  'author': {'login': 'tcojean',\n",
       "   'id': 35342290,\n",
       "   'node_id': 'MDQ6VXNlcjM1MzQyMjkw',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/35342290?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tcojean',\n",
       "   'html_url': 'https://github.com/tcojean',\n",
       "   'followers_url': 'https://api.github.com/users/tcojean/followers',\n",
       "   'following_url': 'https://api.github.com/users/tcojean/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tcojean/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tcojean/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tcojean/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tcojean/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tcojean/repos',\n",
       "   'events_url': 'https://api.github.com/users/tcojean/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tcojean/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'tcojean',\n",
       "   'id': 35342290,\n",
       "   'node_id': 'MDQ6VXNlcjM1MzQyMjkw',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/35342290?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tcojean',\n",
       "   'html_url': 'https://github.com/tcojean',\n",
       "   'followers_url': 'https://api.github.com/users/tcojean/followers',\n",
       "   'following_url': 'https://api.github.com/users/tcojean/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tcojean/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tcojean/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tcojean/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tcojean/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tcojean/repos',\n",
       "   'events_url': 'https://api.github.com/users/tcojean/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tcojean/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': 'b6c4e3c77312c4558770b668972ff41356138eec',\n",
       "    'url': 'https://api.github.com/repos/ginkgo-project/ginkgo/commits/b6c4e3c77312c4558770b668972ff41356138eec',\n",
       "    'html_url': 'https://github.com/ginkgo-project/ginkgo/commit/b6c4e3c77312c4558770b668972ff41356138eec'}],\n",
       "  'stats': {'total': 17, 'additions': 12, 'deletions': 5},\n",
       "  'files': [{'sha': '855e3b9dcc5bb5bbfa3b1f0ebe08c5bc4c5de180',\n",
       "    'filename': 'cuda/stop/residual_norm_reduction_kernels.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 12,\n",
       "    'deletions': 5,\n",
       "    'changes': 17,\n",
       "    'blob_url': 'https://github.com/ginkgo-project/ginkgo/blob/154aafbd57e93e4ede30b1566d2bf03e7c1b096e/cuda%2Fstop%2Fresidual_norm_reduction_kernels.cu',\n",
       "    'raw_url': 'https://github.com/ginkgo-project/ginkgo/raw/154aafbd57e93e4ede30b1566d2bf03e7c1b096e/cuda%2Fstop%2Fresidual_norm_reduction_kernels.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/ginkgo-project/ginkgo/contents/cuda%2Fstop%2Fresidual_norm_reduction_kernels.cu?ref=154aafbd57e93e4ede30b1566d2bf03e7c1b096e',\n",
       "    'patch': '@@ -74,6 +74,14 @@ __global__\\n }\\n \\n \\n+__global__ __launch_bounds__(1) void init_kernel(\\n+    bool *__restrict__ device_storage)\\n+{\\n+    device_storage[0] = true;\\n+    device_storage[1] = false;\\n+}\\n+\\n+\\n template <typename ValueType>\\n void residual_norm_reduction(std::shared_ptr<const CudaExecutor> exec,\\n                              const matrix::Dense<ValueType> *tau,\\n@@ -84,21 +92,20 @@ void residual_norm_reduction(std::shared_ptr<const CudaExecutor> exec,\\n                              Array<bool> *device_storage, bool *all_converged,\\n                              bool *one_changed)\\n {\\n-    /* Represents all_converged, one_changed */\\n-    bool tmp[2] = {true, false};\\n-    exec->copy_from(exec->get_master().get(), 2, tmp,\\n-                    device_storage->get_data());\\n+    init_kernel<<<1, 1>>>(as_cuda_type(device_storage->get_data()));\\n \\n     const dim3 block_size(default_block_size, 1, 1);\\n     const dim3 grid_size(ceildiv(tau->get_size()[1], block_size.x), 1, 1);\\n \\n-    residual_norm_reduction_kernel<<<grid_size, block_size, 0, 0>>>(\\n+    residual_norm_reduction_kernel<<<grid_size, block_size>>>(\\n         tau->get_size()[1], rel_residual_goal,\\n         as_cuda_type(tau->get_const_values()),\\n         as_cuda_type(orig_tau->get_const_values()), stoppingId, setFinalized,\\n         as_cuda_type(stop_status->get_data()),\\n         as_cuda_type(device_storage->get_data()));\\n \\n+    /* Represents all_converged, one_changed */\\n+    bool tmp[2] = {true, false};\\n     exec->get_master()->copy_from(exec.get(), 2,\\n                                   device_storage->get_const_data(), tmp);\\n     *all_converged = tmp[0];'}]},\n",
       " 'https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9': {'sha': 'b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "  'node_id': 'MDY6Q29tbWl0MTMwMDU2NDpiNzg1N2FmNDdmZjJlOGU4MTYyYTI1MGE0YWRlZmJhNTU2ODBiMWM5',\n",
       "  'commit': {'author': {'name': 'maddyscientist',\n",
       "    'email': 'mclark@nvidia.com',\n",
       "    'date': '2019-03-07T23:25:39Z'},\n",
       "   'committer': {'name': 'maddyscientist',\n",
       "    'email': 'mclark@nvidia.com',\n",
       "    'date': '2019-03-07T23:25:39Z'},\n",
       "   'message': 'Fix performance of 4-dslash_domain_Wall_4d.cuh kernels with xpay enabled: store coefficients in __constant__ memory to remove register spilling',\n",
       "   'tree': {'sha': '32acaeccf7a65bc6b6aa72dc2e21021a54348986',\n",
       "    'url': 'https://api.github.com/repos/lattice/quda/git/trees/32acaeccf7a65bc6b6aa72dc2e21021a54348986'},\n",
       "   'url': 'https://api.github.com/repos/lattice/quda/git/commits/b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/lattice/quda/commits/b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "  'html_url': 'https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "  'comments_url': 'https://api.github.com/repos/lattice/quda/commits/b7857af47ff2e8e8162a250a4adefba55680b1c9/comments',\n",
       "  'author': {'login': 'maddyscientist',\n",
       "   'id': 316771,\n",
       "   'node_id': 'MDQ6VXNlcjMxNjc3MQ==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/316771?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/maddyscientist',\n",
       "   'html_url': 'https://github.com/maddyscientist',\n",
       "   'followers_url': 'https://api.github.com/users/maddyscientist/followers',\n",
       "   'following_url': 'https://api.github.com/users/maddyscientist/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/maddyscientist/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/maddyscientist/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/maddyscientist/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/maddyscientist/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/maddyscientist/repos',\n",
       "   'events_url': 'https://api.github.com/users/maddyscientist/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/maddyscientist/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'maddyscientist',\n",
       "   'id': 316771,\n",
       "   'node_id': 'MDQ6VXNlcjMxNjc3MQ==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/316771?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/maddyscientist',\n",
       "   'html_url': 'https://github.com/maddyscientist',\n",
       "   'followers_url': 'https://api.github.com/users/maddyscientist/followers',\n",
       "   'following_url': 'https://api.github.com/users/maddyscientist/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/maddyscientist/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/maddyscientist/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/maddyscientist/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/maddyscientist/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/maddyscientist/repos',\n",
       "   'events_url': 'https://api.github.com/users/maddyscientist/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/maddyscientist/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': 'c5508587476252ddc6062f2d5e1c877f158f7970',\n",
       "    'url': 'https://api.github.com/repos/lattice/quda/commits/c5508587476252ddc6062f2d5e1c877f158f7970',\n",
       "    'html_url': 'https://github.com/lattice/quda/commit/c5508587476252ddc6062f2d5e1c877f158f7970'}],\n",
       "  'stats': {'total': 35, 'additions': 33, 'deletions': 2},\n",
       "  'files': [{'sha': 'e695f2b6f352cb787c3cebda7981d64644e60e1d',\n",
       "    'filename': 'include/kernels/dslash_domain_wall_4d.cuh',\n",
       "    'status': 'modified',\n",
       "    'additions': 20,\n",
       "    'deletions': 2,\n",
       "    'changes': 22,\n",
       "    'blob_url': 'https://github.com/lattice/quda/blob/b7857af47ff2e8e8162a250a4adefba55680b1c9/include%2Fkernels%2Fdslash_domain_wall_4d.cuh',\n",
       "    'raw_url': 'https://github.com/lattice/quda/raw/b7857af47ff2e8e8162a250a4adefba55680b1c9/include%2Fkernels%2Fdslash_domain_wall_4d.cuh',\n",
       "    'contents_url': 'https://api.github.com/repos/lattice/quda/contents/include%2Fkernels%2Fdslash_domain_wall_4d.cuh?ref=b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "    'patch': '@@ -4,6 +4,23 @@\\n \\n namespace quda {\\n \\n+  constexpr int size = 4096;\\n+  static __constant__ char mobius_d[size]; // constant buffer used for Mobius coefficients for GPU kernel\\n+  static void *mobius_h;                   // constant buffer used for Mobius coefficients for CPU kernel\\n+\\n+  /**\\n+     @brief Helper function for grabbing the constant struct, whether\\n+     we are on the GPU or CPU.\\n+  */\\n+  template <typename real>\\n+  inline __device__ __host__ complex<real> a_5(int s) {\\n+#ifdef __CUDA_ARCH__\\n+    return reinterpret_cast<const complex<real>*>(mobius_d)[s];\\n+#else\\n+    return reinterpret_cast<const complex<real>*>(mobius_h)[s];\\n+#endif\\n+  }\\n+\\n   template <typename Float, int nColor, QudaReconstructType reconstruct_>\\n   struct DomainWall4DArg : WilsonArg<Float,nColor,reconstruct_> {\\n     typedef typename mapper<Float>::type real;\\n@@ -18,6 +35,7 @@ namespace quda {\\n     {\\n       if (b_5 == nullptr || c_5 == nullptr) for (int s=0; s<Ls; s++) a_5[s] = a; // 4-d Shamir\\n       else for (int s=0; s<Ls; s++) a_5[s] = 0.5 * a / (b_5[s]*(m_5+4.0) + 1.0); // 4-d Mobius\\n+      mobius_h = a_5;\\n     }\\n   };\\n \\n@@ -39,10 +57,10 @@ namespace quda {\\n     int xs = x_cb + s*arg.dc.volume_4d_cb;\\n     if (xpay && kernel_type == INTERIOR_KERNEL) {\\n       Vector x = arg.x(xs, my_spinor_parity);\\n-      out = x + arg.a_5[s] * out;\\n+      out = x + a_5<real>(s) * out;\\n     } else if (kernel_type != INTERIOR_KERNEL && active) {\\n       Vector x = arg.out(xs, my_spinor_parity);\\n-      out = x + (xpay ? arg.a_5[s] * out : out);\\n+      out = x + (xpay ? a_5<real>(s) * out : out);\\n     }\\n \\n     if (kernel_type != EXTERIOR_KERNEL_ALL || active) arg.out(xs, my_spinor_parity) = out;'},\n",
       "   {'sha': '10a6d39558cbaa3f37e3cc873a0b3f1435122b2c',\n",
       "    'filename': 'lib/dslash4_domain_wall_4d.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 13,\n",
       "    'deletions': 0,\n",
       "    'changes': 13,\n",
       "    'blob_url': 'https://github.com/lattice/quda/blob/b7857af47ff2e8e8162a250a4adefba55680b1c9/lib%2Fdslash4_domain_wall_4d.cu',\n",
       "    'raw_url': 'https://github.com/lattice/quda/raw/b7857af47ff2e8e8162a250a4adefba55680b1c9/lib%2Fdslash4_domain_wall_4d.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/lattice/quda/contents/lib%2Fdslash4_domain_wall_4d.cu?ref=b7857af47ff2e8e8162a250a4adefba55680b1c9',\n",
       "    'patch': '@@ -49,7 +49,20 @@ namespace quda {\\n     void apply(const cudaStream_t &stream) {\\n       TuneParam tp = tuneLaunch(*this, getTuning(), getVerbosity());\\n       Dslash<Float>::setParam(arg);\\n+      typedef typename mapper<Float>::type real;\\n+#ifdef JITIFY\\n+      // we need to break the dslash launch abstraction here to get a handle on the constant memory pointer in the kernel module\\n+      using namespace jitify::reflection;\\n+      const auto kernel = DomainWall4DLaunch<void,0,0,0,false,false,INTERIOR_KERNEL,Arg>::kernel;\\n+      auto instance = Dslash<Float>::program_->kernel(kernel)\\n+        .instantiate(Type<Float>(),nDim,nColor,arg.nParity,arg.dagger,arg.xpay,arg.kernel_type,Type<Arg>());\\n+      cuMemcpyHtoDAsync(instance.get_constant_ptr(\"quda::mobius_d\"), mobius_h, QUDA_MAX_DWF_LS*sizeof(complex<real>), stream);\\n+      Tunable::jitify_error = instance.configure(tp.grid,tp.block,tp.shared_bytes,stream).launch(arg);\\n+#else\\n+      cudaMemcpyToSymbolAsync(mobius_d, mobius_h, QUDA_MAX_DWF_LS*sizeof(complex<real>), 0,\\n+                              cudaMemcpyHostToDevice, streams[Nstream-1]);\\n       Dslash<Float>::template instantiate<DomainWall4DLaunch,nDim,nColor>(tp, arg, stream);\\n+#endif\\n     }\\n \\n     TuneKey tuneKey() const { return TuneKey(in.VolString(), typeid(*this).name(), Dslash<Float>::aux[arg.kernel_type]); }'}]},\n",
       " 'https://github.com/gromacs/gromacs/commit/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446': {'sha': '3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446',\n",
       "  'node_id': 'MDY6Q29tbWl0MjIwMTY0OjNlNTJjODJiOGZmYTExYmZhMzE4Mzk2ZWI4ZTg2Y2JkMGY5Yjc0NDY=',\n",
       "  'commit': {'author': {'name': 'Szilárd Páll',\n",
       "    'email': 'pall.szilard@gmail.com',\n",
       "    'date': '2021-01-19T12:09:15Z'},\n",
       "   'committer': {'name': 'Paul Bauer',\n",
       "    'email': 'paul.bauer.q@gmail.com',\n",
       "    'date': '2021-01-19T12:09:15Z'},\n",
       "   'message': 'Disable CUDA textures on NVIDIA Volta\\n\\nThis has significant performance benefit for the nbnxm kernels with\\ntabulated Ewald correction and it has negligible impact on the PME kernels.\\n\\nPartially addresses #3845',\n",
       "   'tree': {'sha': 'c23c8374695af6e16ce866f1f8210f86b6251eaa',\n",
       "    'url': 'https://api.github.com/repos/gromacs/gromacs/git/trees/c23c8374695af6e16ce866f1f8210f86b6251eaa'},\n",
       "   'url': 'https://api.github.com/repos/gromacs/gromacs/git/commits/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/gromacs/gromacs/commits/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446',\n",
       "  'html_url': 'https://github.com/gromacs/gromacs/commit/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446',\n",
       "  'comments_url': 'https://api.github.com/repos/gromacs/gromacs/commits/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446/comments',\n",
       "  'author': {'login': 'pszi1ard',\n",
       "   'id': 1333767,\n",
       "   'node_id': 'MDQ6VXNlcjEzMzM3Njc=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/1333767?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/pszi1ard',\n",
       "   'html_url': 'https://github.com/pszi1ard',\n",
       "   'followers_url': 'https://api.github.com/users/pszi1ard/followers',\n",
       "   'following_url': 'https://api.github.com/users/pszi1ard/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/pszi1ard/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/pszi1ard/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/pszi1ard/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/pszi1ard/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/pszi1ard/repos',\n",
       "   'events_url': 'https://api.github.com/users/pszi1ard/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/pszi1ard/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'acmnpv',\n",
       "   'id': 6458216,\n",
       "   'node_id': 'MDQ6VXNlcjY0NTgyMTY=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/6458216?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/acmnpv',\n",
       "   'html_url': 'https://github.com/acmnpv',\n",
       "   'followers_url': 'https://api.github.com/users/acmnpv/followers',\n",
       "   'following_url': 'https://api.github.com/users/acmnpv/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/acmnpv/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/acmnpv/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/acmnpv/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/acmnpv/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/acmnpv/repos',\n",
       "   'events_url': 'https://api.github.com/users/acmnpv/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/acmnpv/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': '7f06d1572cbf8a1e067ef97aecf18dc747a72497',\n",
       "    'url': 'https://api.github.com/repos/gromacs/gromacs/commits/7f06d1572cbf8a1e067ef97aecf18dc747a72497',\n",
       "    'html_url': 'https://github.com/gromacs/gromacs/commit/7f06d1572cbf8a1e067ef97aecf18dc747a72497'}],\n",
       "  'stats': {'total': 6, 'additions': 4, 'deletions': 2},\n",
       "  'files': [{'sha': 'f3484d5d569a64b75909dabf8c9be7cf1767c19a',\n",
       "    'filename': 'src/gromacs/gpu_utils/cuda_arch_utils.cuh',\n",
       "    'status': 'modified',\n",
       "    'additions': 4,\n",
       "    'deletions': 2,\n",
       "    'changes': 6,\n",
       "    'blob_url': 'https://github.com/gromacs/gromacs/blob/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446/src%2Fgromacs%2Fgpu_utils%2Fcuda_arch_utils.cuh',\n",
       "    'raw_url': 'https://github.com/gromacs/gromacs/raw/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446/src%2Fgromacs%2Fgpu_utils%2Fcuda_arch_utils.cuh',\n",
       "    'contents_url': 'https://api.github.com/repos/gromacs/gromacs/contents/src%2Fgromacs%2Fgpu_utils%2Fcuda_arch_utils.cuh?ref=3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446',\n",
       "    'patch': '@@ -2,7 +2,7 @@\\n  * This file is part of the GROMACS molecular simulation package.\\n  *\\n  * Copyright (c) 2012,2014,2015,2016,2017 by the GROMACS development team.\\n- * Copyright (c) 2018,2019,2020, by the GROMACS development team, led by\\n+ * Copyright (c) 2018,2019,2020,2021, by the GROMACS development team, led by\\n  * Mark Abraham, David van der Spoel, Berk Hess, and Erik Lindahl,\\n  * and including many others, as listed in the AUTHORS file in the\\n  * top-level source directory and at http://www.gromacs.org.\\n@@ -69,12 +69,14 @@ static const unsigned int c_fullWarpMask = 0xffffffff;\\n  *\\n  *  Only texture objects supported.\\n  *  Disable texture support missing in clang (all versions up to <=5.0-dev as of writing).\\n+ *  Disable texture support on CC 7.0 for performance reasons (Issue #3845).\\n  *\\n  *  This option will not influence functionality. All features using textures ought\\n  *  to have fallback for texture-less reads (direct/LDG loads), all new code needs\\n  *  to provide fallback code.\\n  */\\n-#if defined(GMX_DISABLE_CUDA_TEXTURES) || (defined(__clang__) && defined(__CUDA__))\\n+#if defined(GMX_DISABLE_CUDA_TEXTURES) || (defined(__clang__) && defined(__CUDA__)) \\\\\\n+        || (GMX_PTX_ARCH == 700)\\n #    define DISABLE_CUDA_TEXTURES 1\\n #else\\n #    define DISABLE_CUDA_TEXTURES 0'}]},\n",
       " 'https://github.com/gromacs/gromacs/commit/8aa14d11ff775055794360a655fe800deea298a8': {'sha': '8aa14d11ff775055794360a655fe800deea298a8',\n",
       "  'node_id': 'MDY6Q29tbWl0MjIwMTY0OjhhYTE0ZDExZmY3NzUwNTU3OTQzNjBhNjU1ZmU4MDBkZWVhMjk4YTg=',\n",
       "  'commit': {'author': {'name': 'Alan Gray',\n",
       "    'email': 'alangray3@gmail.com',\n",
       "    'date': '2020-12-18T07:45:10Z'},\n",
       "   'committer': {'name': 'Alan Gray',\n",
       "    'email': 'alangray3@gmail.com',\n",
       "    'date': '2020-12-18T08:53:19Z'},\n",
       "   'message': 'Stage bonded kernel atomics through shared memory\\n\\nFixes performance bug introduced in 01b2f20bd5 by staging energy step\\natomics through shared memory rather than have all threads write\\natomically directly to global memory.\\n\\nFixes #3443',\n",
       "   'tree': {'sha': 'f3d4e770417257ca3d78f6a2da2aa0799cdb6b4d',\n",
       "    'url': 'https://api.github.com/repos/gromacs/gromacs/git/trees/f3d4e770417257ca3d78f6a2da2aa0799cdb6b4d'},\n",
       "   'url': 'https://api.github.com/repos/gromacs/gromacs/git/commits/8aa14d11ff775055794360a655fe800deea298a8',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/gromacs/gromacs/commits/8aa14d11ff775055794360a655fe800deea298a8',\n",
       "  'html_url': 'https://github.com/gromacs/gromacs/commit/8aa14d11ff775055794360a655fe800deea298a8',\n",
       "  'comments_url': 'https://api.github.com/repos/gromacs/gromacs/commits/8aa14d11ff775055794360a655fe800deea298a8/comments',\n",
       "  'author': {'login': 'agray3',\n",
       "   'id': 10851179,\n",
       "   'node_id': 'MDQ6VXNlcjEwODUxMTc5',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/10851179?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/agray3',\n",
       "   'html_url': 'https://github.com/agray3',\n",
       "   'followers_url': 'https://api.github.com/users/agray3/followers',\n",
       "   'following_url': 'https://api.github.com/users/agray3/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/agray3/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/agray3/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/agray3/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/agray3/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/agray3/repos',\n",
       "   'events_url': 'https://api.github.com/users/agray3/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/agray3/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'agray3',\n",
       "   'id': 10851179,\n",
       "   'node_id': 'MDQ6VXNlcjEwODUxMTc5',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/10851179?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/agray3',\n",
       "   'html_url': 'https://github.com/agray3',\n",
       "   'followers_url': 'https://api.github.com/users/agray3/followers',\n",
       "   'following_url': 'https://api.github.com/users/agray3/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/agray3/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/agray3/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/agray3/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/agray3/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/agray3/repos',\n",
       "   'events_url': 'https://api.github.com/users/agray3/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/agray3/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': 'c1a0727c81b010ef83b8c878513b8d58299b236c',\n",
       "    'url': 'https://api.github.com/repos/gromacs/gromacs/commits/c1a0727c81b010ef83b8c878513b8d58299b236c',\n",
       "    'html_url': 'https://github.com/gromacs/gromacs/commit/c1a0727c81b010ef83b8c878513b8d58299b236c'}],\n",
       "  'stats': {'total': 55, 'additions': 47, 'deletions': 8},\n",
       "  'files': [{'sha': '24b8eb1655eecea230cc01c6ed95abb921d58722',\n",
       "    'filename': 'src/gromacs/listed_forces/gpubonded_impl.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 2,\n",
       "    'deletions': 0,\n",
       "    'changes': 2,\n",
       "    'blob_url': 'https://github.com/gromacs/gromacs/blob/8aa14d11ff775055794360a655fe800deea298a8/src%2Fgromacs%2Flisted_forces%2Fgpubonded_impl.cu',\n",
       "    'raw_url': 'https://github.com/gromacs/gromacs/raw/8aa14d11ff775055794360a655fe800deea298a8/src%2Fgromacs%2Flisted_forces%2Fgpubonded_impl.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/gromacs/gromacs/contents/src%2Fgromacs%2Flisted_forces%2Fgpubonded_impl.cu?ref=8aa14d11ff775055794360a655fe800deea298a8',\n",
       "    'patch': '@@ -115,6 +115,8 @@ GpuBonded::Impl::Impl(const gmx_ffparams_t& ffparams,\\n     kernelLaunchConfig_.gridSize[0]  = (fTypeRangeEnd + c_threadsPerBlock) / c_threadsPerBlock;\\n     kernelLaunchConfig_.gridSize[1]  = 1;\\n     kernelLaunchConfig_.gridSize[2]  = 1;\\n+    kernelLaunchConfig_.sharedMemorySize =\\n+            SHIFTS * sizeof(float3) + (c_threadsPerBlock / warp_size) * 3 * sizeof(float);\\n }\\n \\n GpuBonded::Impl::~Impl()'},\n",
       "   {'sha': 'b123efefd6f083575cc39d8b3b6e56d96fab3400',\n",
       "    'filename': 'src/gromacs/listed_forces/gpubondedkernels.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 45,\n",
       "    'deletions': 8,\n",
       "    'changes': 53,\n",
       "    'blob_url': 'https://github.com/gromacs/gromacs/blob/8aa14d11ff775055794360a655fe800deea298a8/src%2Fgromacs%2Flisted_forces%2Fgpubondedkernels.cu',\n",
       "    'raw_url': 'https://github.com/gromacs/gromacs/raw/8aa14d11ff775055794360a655fe800deea298a8/src%2Fgromacs%2Flisted_forces%2Fgpubondedkernels.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/gromacs/gromacs/contents/src%2Fgromacs%2Flisted_forces%2Fgpubondedkernels.cu?ref=8aa14d11ff775055794360a655fe800deea298a8',\n",
       "    'patch': '@@ -723,11 +723,15 @@ template<bool calcVir, bool calcEner>\\n __global__ void exec_kernel_gpu(BondedCudaKernelParameters kernelParams)\\n {\\n     assert(blockDim.y == 1 && blockDim.z == 1);\\n-    const int  tid          = blockIdx.x * blockDim.x + threadIdx.x;\\n-    float      vtot_loc     = 0;\\n-    float      vtotVdw_loc  = 0;\\n-    float      vtotElec_loc = 0;\\n-    __shared__ float3 sm_fShiftLoc[SHIFTS];\\n+    const int tid          = blockIdx.x * blockDim.x + threadIdx.x;\\n+    float     vtot_loc     = 0;\\n+    float     vtotVdw_loc  = 0;\\n+    float     vtotElec_loc = 0;\\n+\\n+    extern __shared__ char sm_dynamicShmem[];\\n+    char*                  sm_nextSlotPtr = sm_dynamicShmem;\\n+    float3*                sm_fShiftLoc   = (float3*)sm_nextSlotPtr;\\n+    sm_nextSlotPtr += SHIFTS * sizeof(float3);\\n \\n     if (calcVir)\\n     {\\n@@ -802,9 +806,42 @@ __global__ void exec_kernel_gpu(BondedCudaKernelParameters kernelParams)\\n     {\\n         float* vtotVdw  = kernelParams.d_vTot + F_LJ14;\\n         float* vtotElec = kernelParams.d_vTot + F_COUL14;\\n-        atomicAdd(kernelParams.d_vTot + fType, vtot_loc);\\n-        atomicAdd(vtotVdw, vtotVdw_loc);\\n-        atomicAdd(vtotElec, vtotElec_loc);\\n+\\n+        // Stage atomic accumulation through shared memory:\\n+        // each warp will accumulate its own partial sum\\n+        // and then a single thread per warp will accumulate this to the global sum\\n+\\n+        int numWarps = blockDim.x / warpSize;\\n+        int warpId   = threadIdx.x / warpSize;\\n+\\n+        // Shared memory variables to hold block-local partial sum\\n+        float* sm_vTot = (float*)sm_nextSlotPtr;\\n+        sm_nextSlotPtr += numWarps * sizeof(float);\\n+        float* sm_vTotVdw = (float*)sm_nextSlotPtr;\\n+        sm_nextSlotPtr += numWarps * sizeof(float);\\n+        float* sm_vTotElec = (float*)sm_nextSlotPtr;\\n+\\n+        if (threadIdx.x % warpSize == 0)\\n+        {\\n+            // One thread per warp initializes to zero\\n+            sm_vTot[warpId]     = 0.;\\n+            sm_vTotVdw[warpId]  = 0.;\\n+            sm_vTotElec[warpId] = 0.;\\n+        }\\n+        __syncwarp(); // All threads in warp must wait for initialization\\n+\\n+        // Perform warp-local accumulation in shared memory\\n+        atomicAdd(sm_vTot + warpId, vtot_loc);\\n+        atomicAdd(sm_vTotVdw + warpId, vtotVdw_loc);\\n+        atomicAdd(sm_vTotElec + warpId, vtotElec_loc);\\n+\\n+        __syncwarp(); // Ensure all threads in warp have completed\\n+        if (threadIdx.x % warpSize == 0)\\n+        { // One thread per warp accumulates partial sum into global sum\\n+            atomicAdd(kernelParams.d_vTot + fType, sm_vTot[warpId]);\\n+            atomicAdd(vtotVdw, sm_vTotVdw[warpId]);\\n+            atomicAdd(vtotElec, sm_vTotElec[warpId]);\\n+        }\\n     }\\n     /* Accumulate shift vectors from shared memory to global memory on the first SHIFTS threads of the block. */\\n     if (calcVir)'}]},\n",
       " 'https://github.com/arrayfire/arrayfire/commit/d8d8c439c8d0a43c0f92b11fd06133be80754ab8': {'sha': 'd8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "  'node_id': 'MDY6Q29tbWl0MjU4ODk4MDI6ZDhkOGM0MzljOGQwYTQzYzBmOTJiMTFmZDA2MTMzYmU4MDc1NGFiOA==',\n",
       "  'commit': {'author': {'name': 'pradeep',\n",
       "    'email': 'pradeep@arrayfire.com',\n",
       "    'date': '2020-03-04T11:48:26Z'},\n",
       "   'committer': {'name': 'Umar Arshad',\n",
       "    'email': 'umar@arrayfire.com',\n",
       "    'date': '2020-03-27T22:39:56Z'},\n",
       "   'message': 'Move orb LUT in CUDA backend to texture memory\\n\\ncuda::kernel::extract_orb is the CUDA kernel that uses the orb\\nlookup table. Shared below is performance of the kernel using constant\\nmemory vs texture memory. There is neglible to no difference between two\\nversions. Hence, shifted to texture memory LUT to reduce global constant\\nmemory usage.\\n\\nPerformance using constant memory LUT\\n-------------------------------------\\n\\nTime(%)  Time   Calls      Avg       Min       Max  Name\\n\\n3.02%  292.26us   24  12.177us  11.360us  14.528us  void cuda::kernel::extract_orb<float>\\n2.16%  209.00us   16  13.062us  11.616us  16.033us  void cuda::kernel::extract_orb<double>\\n\\nPerformance using texture LUT\\n-----------------------------\\n\\nTime(%)    Time   Calls      Avg       Min       Max  Name\\n\\n2.84%  270.63us     24  11.276us  9.6970us  15.040us  void cuda::kernel::extract_orb<float>\\n2.20%  209.28us     16  13.080us  10.688us  16.960us  void cuda::kernel::extract_orb<double>',\n",
       "   'tree': {'sha': 'e243030c26485b03d34857dc5f7ef5a90936a4e6',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/trees/e243030c26485b03d34857dc5f7ef5a90936a4e6'},\n",
       "   'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/commits/d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "  'html_url': 'https://github.com/arrayfire/arrayfire/commit/d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "  'comments_url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/comments',\n",
       "  'author': {'login': '9prady9',\n",
       "   'id': 3270458,\n",
       "   'node_id': 'MDQ6VXNlcjMyNzA0NTg=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/3270458?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/9prady9',\n",
       "   'html_url': 'https://github.com/9prady9',\n",
       "   'followers_url': 'https://api.github.com/users/9prady9/followers',\n",
       "   'following_url': 'https://api.github.com/users/9prady9/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/9prady9/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/9prady9/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/9prady9/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/9prady9/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/9prady9/repos',\n",
       "   'events_url': 'https://api.github.com/users/9prady9/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/9prady9/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'umar456',\n",
       "   'id': 457510,\n",
       "   'node_id': 'MDQ6VXNlcjQ1NzUxMA==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/457510?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/umar456',\n",
       "   'html_url': 'https://github.com/umar456',\n",
       "   'followers_url': 'https://api.github.com/users/umar456/followers',\n",
       "   'following_url': 'https://api.github.com/users/umar456/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/umar456/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/umar456/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/umar456/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/umar456/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/umar456/repos',\n",
       "   'events_url': 'https://api.github.com/users/umar456/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/umar456/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': '113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'html_url': 'https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50'}],\n",
       "  'stats': {'total': 73, 'additions': 42, 'deletions': 31},\n",
       "  'files': [{'sha': '15ef584bb0621f5d6894e723befa867e0cacbca8',\n",
       "    'filename': 'src/backend/cuda/kernel/orb.hpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 22,\n",
       "    'deletions': 19,\n",
       "    'changes': 41,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Fkernel%2Forb.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Fkernel%2Forb.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Fkernel%2Forb.hpp?ref=d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "    'patch': '@@ -9,28 +9,26 @@\\n \\n #pragma once\\n \\n+#include <LookupTable1D.hpp>\\n #include <common/dispatch.hpp>\\n #include <debug_cuda.hpp>\\n-#include <err_cuda.hpp>\\n+#include <kernel/convolve.hpp>\\n+#include <kernel/orb_patch.hpp>\\n+#include <kernel/range.hpp>\\n+#include <kernel/sort_by_key.hpp>\\n #include <memory.hpp>\\n \\n-#include \"convolve.hpp\"\\n-#include \"orb_patch.hpp\"\\n-#include \"range.hpp\"\\n-#include \"sort_by_key.hpp\"\\n-\\n using std::unique_ptr;\\n using std::vector;\\n \\n namespace cuda {\\n-\\n namespace kernel {\\n \\n-static const int THREADS   = 256;\\n-static const int THREADS_X = 16;\\n-static const int THREADS_Y = 16;\\n+constexpr int THREADS   = 256;\\n+constexpr int THREADS_X = 16;\\n+constexpr int THREADS_Y = 16;\\n \\n-static const float PI_VAL = 3.14159265358979323846f;\\n+constexpr float PI_VAL = 3.14159265358979323846f;\\n \\n template<typename T>\\n void gaussian1D(T* out, const int dim, double sigma = 0.0) {\\n@@ -213,12 +211,17 @@ inline __device__ T get_pixel(unsigned x, unsigned y, const float ori,\\n     return image.ptr[x * image.dims[0] + y];\\n }\\n \\n+inline __device__ int lookup(const int n, cudaTextureObject_t tex) {\\n+    return tex1Dfetch<int>(tex, n);\\n+}\\n+\\n template<typename T>\\n __global__ void extract_orb(unsigned* desc_out, const unsigned n_feat,\\n                             float* x_in_out, float* y_in_out,\\n                             const float* ori_in, float* size_out,\\n                             CParam<T> image, const float scl,\\n-                            const unsigned patch_size) {\\n+                            const unsigned patch_size,\\n+                            cudaTextureObject_t luTable) {\\n     unsigned f = blockDim.x * blockIdx.x + threadIdx.x;\\n \\n     if (f < n_feat) {\\n@@ -240,13 +243,13 @@ __global__ void extract_orb(unsigned* desc_out, const unsigned n_feat,\\n             for (unsigned j = 0; j < 16; j++) {\\n                 // Get position from distribution pattern and values of points\\n                 // p1 and p2\\n-                int dist_x = d_ref_pat[i * 16 * 4 + j * 4];\\n-                int dist_y = d_ref_pat[i * 16 * 4 + j * 4 + 1];\\n+                int dist_x = lookup(i * 16 * 4 + j * 4, luTable);\\n+                int dist_y = lookup(i * 16 * 4 + j * 4 + 1, luTable);\\n                 T p1       = get_pixel(x, y, ori, size, dist_x, dist_y, image,\\n                                  patch_size);\\n \\n-                dist_x = d_ref_pat[i * 16 * 4 + j * 4 + 2];\\n-                dist_y = d_ref_pat[i * 16 * 4 + j * 4 + 3];\\n+                dist_x = lookup(i * 16 * 4 + j * 4 + 2, luTable);\\n+                dist_y = lookup(i * 16 * 4 + j * 4 + 3, luTable);\\n                 T p2   = get_pixel(x, y, ori, size, dist_x, dist_y, image,\\n                                  patch_size);\\n \\n@@ -274,7 +277,8 @@ void orb(unsigned* out_feat, float** d_x, float** d_y, float** d_score,\\n          vector<float*>& d_y_pyr, vector<unsigned>& lvl_best,\\n          vector<float>& lvl_scl, vector<Array<T>>& img_pyr,\\n          const float fast_thr, const unsigned max_feat, const float scl_fctr,\\n-         const unsigned levels, const bool blur_img) {\\n+         const unsigned levels, const bool blur_img,\\n+         const LookupTable1D<int>& luTable) {\\n     UNUSED(fast_thr);\\n     UNUSED(max_feat);\\n     UNUSED(scl_fctr);\\n@@ -381,7 +385,7 @@ void orb(unsigned* out_feat, float** d_x, float** d_y, float** d_score,\\n         blocks  = dim3(divup(feat_pyr[i], threads.x), 1);\\n         CUDA_LAUNCH((extract_orb<T>), blocks, threads, d_desc_lvl, feat_pyr[i],\\n                     d_x_lvl, d_y_lvl, d_ori_lvl, d_size_lvl, img_pyr[i],\\n-                    lvl_scl[i], patch_size);\\n+                    lvl_scl[i], patch_size, luTable.get());\\n         POST_LAUNCH_CHECK();\\n \\n         // Store results to pyramids\\n@@ -446,5 +450,4 @@ void orb(unsigned* out_feat, float** d_x, float** d_y, float** d_score,\\n }\\n \\n }  // namespace kernel\\n-\\n }  // namespace cuda'},\n",
       "   {'sha': '6dfe3fb03712e7f8ae7f4ba7241995ea2aa777ed',\n",
       "    'filename': 'src/backend/cuda/kernel/orb_patch.hpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 5,\n",
       "    'deletions': 8,\n",
       "    'changes': 13,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Fkernel%2Forb_patch.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Fkernel%2Forb_patch.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Fkernel%2Forb_patch.hpp?ref=d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "    'patch': '@@ -10,19 +10,18 @@\\n #pragma once\\n \\n namespace cuda {\\n-namespace kernel {\\n \\n // Reference pattern, generated for a patch size of 31x31, as suggested by\\n // original ORB paper\\n-#define REF_PAT_SIZE 31\\n-#define REF_PAT_SAMPLES 256\\n-#define REF_PAT_COORDS 4\\n-#define REF_PAT_LENGTH (REF_PAT_SAMPLES * REF_PAT_COORDS)\\n+constexpr unsigned REF_PAT_SIZE    = 31;\\n+constexpr unsigned REF_PAT_SAMPLES = 256;\\n+constexpr unsigned REF_PAT_COORDS  = 4;\\n+constexpr unsigned REF_PAT_LENGTH  = (REF_PAT_SAMPLES * REF_PAT_COORDS);\\n \\n // Current reference pattern was borrowed from OpenCV, a randomly generated\\n // pattern will not achieve same quality as it must be trained like described\\n // in sections 4.2 and 4.3 of the original ORB paper.\\n-__constant__ int d_ref_pat[REF_PAT_LENGTH] = {\\n+int d_ref_pat[REF_PAT_LENGTH] = {\\n     8,   -3,  9,   5,   4,   2,   7,   -12, -11, 9,   -8,  2,   7,   -12, 12,\\n     -13, 2,   -13, 2,   12,  1,   -7,  1,   6,   -2,  -10, -2,  -4,  -13, -13,\\n     -11, -8,  -13, -3,  -12, -9,  10,  4,   11,  9,   -13, -8,  -8,  -9,  -11,\\n@@ -94,6 +93,4 @@ __constant__ int d_ref_pat[REF_PAT_LENGTH] = {\\n     -1,  -6,  0,   -11,\\n };\\n \\n-}  // namespace kernel\\n-\\n }  // namespace cuda'},\n",
       "   {'sha': '86e463ed426ae7359f322c71e8217baa64ea73fb',\n",
       "    'filename': 'src/backend/cuda/orb.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 15,\n",
       "    'deletions': 4,\n",
       "    'changes': 19,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Forb.cu',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/d8d8c439c8d0a43c0f92b11fd06133be80754ab8/src%2Fbackend%2Fcuda%2Forb.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Forb.cu?ref=d8d8c439c8d0a43c0f92b11fd06133be80754ab8',\n",
       "    'patch': '@@ -7,13 +7,18 @@\\n  * http://arrayfire.com/licenses/BSD-3-Clause\\n  ********************************************************/\\n \\n+#include <orb.hpp>\\n+\\n #include <Array.hpp>\\n+#include <LookupTable1D.hpp>\\n #include <err_cuda.hpp>\\n #include <fast_pyramid.hpp>\\n #include <kernel/orb.hpp>\\n #include <kernel/orb_patch.hpp>\\n #include <af/dim4.hpp>\\n \\n+#include <type_traits>\\n+\\n using af::dim4;\\n \\n namespace cuda {\\n@@ -52,10 +57,16 @@ unsigned orb(Array<float> &x, Array<float> &y, Array<float> &score,\\n     float *size_out;\\n     unsigned *desc_out;\\n \\n-    kernel::orb<T, convAccT>(&nfeat_out, &x_out, &y_out, &score_out,\\n-                             &orientation_out, &size_out, &desc_out, feat_pyr,\\n-                             d_x_pyr, d_y_pyr, lvl_best, lvl_scl, img_pyr,\\n-                             fast_thr, max_feat, scl_fctr, levels, blur_img);\\n+    // TODO(pradeep) Figure out a better way to create lut Array only once\\n+    const Array<int> lut = createHostDataArray(\\n+        af::dim4(sizeof(d_ref_pat) / sizeof(int)), d_ref_pat);\\n+\\n+    LookupTable1D<int> orbLUT(lut);\\n+\\n+    kernel::orb<T, convAccT>(\\n+        &nfeat_out, &x_out, &y_out, &score_out, &orientation_out, &size_out,\\n+        &desc_out, feat_pyr, d_x_pyr, d_y_pyr, lvl_best, lvl_scl, img_pyr,\\n+        fast_thr, max_feat, scl_fctr, levels, blur_img, orbLUT);\\n \\n     if (nfeat_out > 0) {\\n         if (x_out == NULL || y_out == NULL || score_out == NULL ||'}]},\n",
       " 'https://github.com/lattice/quda/commit/0dd4f75396999b649c759946fe0b53e6cd12aae0': {'sha': '0dd4f75396999b649c759946fe0b53e6cd12aae0',\n",
       "  'node_id': 'MDY6Q29tbWl0MTMwMDU2NDowZGQ0Zjc1Mzk2OTk5YjY0OWM3NTk5NDZmZTBiNTNlNmNkMTJhYWUw',\n",
       "  'commit': {'author': {'name': 'maddyscientist',\n",
       "    'email': 'mclark@nvidia.com',\n",
       "    'date': '2017-09-25T22:46:30Z'},\n",
       "   'committer': {'name': 'maddyscientist',\n",
       "    'email': 'mclark@nvidia.com',\n",
       "    'date': '2017-09-25T22:46:30Z'},\n",
       "   'message': 'Added shared memory carve out setting for Volta - improves dslash performance by ~5%',\n",
       "   'tree': {'sha': 'db21e98bf133515b448bb320ca161a58a1917a85',\n",
       "    'url': 'https://api.github.com/repos/lattice/quda/git/trees/db21e98bf133515b448bb320ca161a58a1917a85'},\n",
       "   'url': 'https://api.github.com/repos/lattice/quda/git/commits/0dd4f75396999b649c759946fe0b53e6cd12aae0',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/lattice/quda/commits/0dd4f75396999b649c759946fe0b53e6cd12aae0',\n",
       "  'html_url': 'https://github.com/lattice/quda/commit/0dd4f75396999b649c759946fe0b53e6cd12aae0',\n",
       "  'comments_url': 'https://api.github.com/repos/lattice/quda/commits/0dd4f75396999b649c759946fe0b53e6cd12aae0/comments',\n",
       "  'author': {'login': 'maddyscientist',\n",
       "   'id': 316771,\n",
       "   'node_id': 'MDQ6VXNlcjMxNjc3MQ==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/316771?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/maddyscientist',\n",
       "   'html_url': 'https://github.com/maddyscientist',\n",
       "   'followers_url': 'https://api.github.com/users/maddyscientist/followers',\n",
       "   'following_url': 'https://api.github.com/users/maddyscientist/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/maddyscientist/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/maddyscientist/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/maddyscientist/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/maddyscientist/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/maddyscientist/repos',\n",
       "   'events_url': 'https://api.github.com/users/maddyscientist/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/maddyscientist/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'maddyscientist',\n",
       "   'id': 316771,\n",
       "   'node_id': 'MDQ6VXNlcjMxNjc3MQ==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/316771?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/maddyscientist',\n",
       "   'html_url': 'https://github.com/maddyscientist',\n",
       "   'followers_url': 'https://api.github.com/users/maddyscientist/followers',\n",
       "   'following_url': 'https://api.github.com/users/maddyscientist/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/maddyscientist/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/maddyscientist/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/maddyscientist/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/maddyscientist/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/maddyscientist/repos',\n",
       "   'events_url': 'https://api.github.com/users/maddyscientist/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/maddyscientist/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': 'a835f370cfeecdccd57bcaaefc43d40e13918a0b',\n",
       "    'url': 'https://api.github.com/repos/lattice/quda/commits/a835f370cfeecdccd57bcaaefc43d40e13918a0b',\n",
       "    'html_url': 'https://github.com/lattice/quda/commit/a835f370cfeecdccd57bcaaefc43d40e13918a0b'}],\n",
       "  'stats': {'total': 28, 'additions': 28, 'deletions': 0},\n",
       "  'files': [{'sha': '8ef65cc54ebc51563bcd8bf3fb99cd3bffdcef8c',\n",
       "    'filename': 'lib/dslash_quda.cuh',\n",
       "    'status': 'modified',\n",
       "    'additions': 28,\n",
       "    'deletions': 0,\n",
       "    'changes': 28,\n",
       "    'blob_url': 'https://github.com/lattice/quda/blob/0dd4f75396999b649c759946fe0b53e6cd12aae0/lib%2Fdslash_quda.cuh',\n",
       "    'raw_url': 'https://github.com/lattice/quda/raw/0dd4f75396999b649c759946fe0b53e6cd12aae0/lib%2Fdslash_quda.cuh',\n",
       "    'contents_url': 'https://api.github.com/repos/lattice/quda/contents/lib%2Fdslash_quda.cuh?ref=0dd4f75396999b649c759946fe0b53e6cd12aae0',\n",
       "    'patch': '@@ -1,20 +1,33 @@\\n //#define DSLASH_TUNE_TILE\\n \\n+#if (__COMPUTE_CAPABILITY__ >= 700)\\n+// for running on Volta we set large shared memory mode to prefer hitting in L2\\n+#define SET_CACHE(x) cudaFuncSetAttribute(x, cudaFuncAttributePreferredSharedMemoryCarveout, (int)cudaSharedmemCarveoutMaxShared)\\n+#else\\n+#define SET_CACHE(x)\\n+#endif\\n+\\n #define EVEN_MORE_GENERIC_DSLASH(FUNC, FLOAT, DAG, X, kernel_type, gridDim, blockDim, shared, stream, param) \\\\\\n   if (x==0) {\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## Kernel<kernel_type> );\\t\\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## Kernel<kernel_type> );\\t\\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_8) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## Kernel<kernel_type> );\\t\\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   } else {\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_8) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## X ## Kernel<kernel_type> <<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   }\\n@@ -160,10 +173,13 @@\\n \\n #define EVEN_MORE_GENERIC_ASYM_DSLASH(FUNC, FLOAT, DAG, X, kernel_type, gridDim, blockDim, shared, stream, param) \\\\\\n   if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+    SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n     FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n   } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+    SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n     FUNC ## FLOAT ## 12 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n   } else if (reconstruct == QUDA_RECONSTRUCT_8) {\\t\\t\\t\\\\\\n+    SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n     FUNC ## FLOAT ## 8 ## DAG ## X ## Kernel<kernel_type> <<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n   }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n \\n@@ -231,34 +247,46 @@\\n #define EVEN_MORE_GENERIC_NDEG_TM_DSLASH(FUNC, FLOAT, DAG, X, kernel_type, gridDim, blockDim, shared, stream, param) \\\\\\n   if (x == 0 && d == 0) {\\t\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## Twist ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## Twist ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## Twist ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## Twist ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else {\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## Twist ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## Twist ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   } else if (x != 0 && d == 0) {\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## Twist ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## Twist ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## Twist ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## Twist ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_8) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## Twist ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## Twist ## X ## Kernel<kernel_type> <<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   } else if (x == 0 && d != 0) {\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else {\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   } else{\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n     if (reconstruct == QUDA_RECONSTRUCT_NO) {\\t\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 18 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_12) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 12 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 12 ## DAG ## X ## Kernel<kernel_type><<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     } else if (reconstruct == QUDA_RECONSTRUCT_8) {\\t\\t\\t\\\\\\n+      SET_CACHE( FUNC ## FLOAT ## 8 ## DAG ## X ## Kernel<kernel_type> ); \\\\\\n       FUNC ## FLOAT ## 8 ## DAG ## X ## Kernel<kernel_type> <<<gridDim, blockDim, shared, stream>>> (param); \\\\\\n     }\\t\\t\\t\\t\\t\\t\\t\\t\\t\\\\\\n   }'}]},\n",
       " 'https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50': {'sha': '113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "  'node_id': 'MDY6Q29tbWl0MjU4ODk4MDI6MTEzY2IxODE2MGEzMWQ4ZWUwNGQxMTk2OWJjNTdmZjE2MjhiZGE1MA==',\n",
       "  'commit': {'author': {'name': 'pradeep',\n",
       "    'email': 'pradeep@arrayfire.com',\n",
       "    'date': '2020-03-04T09:00:12Z'},\n",
       "   'committer': {'name': 'Umar Arshad',\n",
       "    'email': 'umar@arrayfire.com',\n",
       "    'date': '2020-03-27T22:39:56Z'},\n",
       "   'message': 'Move fast LUT in CUDA backend to texture memory\\n\\ncuda::kernel::locate_features is the CUDA kernel that uses the fast\\nlookup table. Shared below is performance of the kernel using constant\\nmemory vs texture memory. There is neglible to no difference between two\\nversions. Hence, shifted to texture memory LUT to reduce global constant\\nmemory usage.\\n\\nPerformance using constant memory LUT\\n-------------------------------------\\n\\nTime(%)    Time   Calls      Avg       Min       Max  Name\\n1.48%  101.09us      3  33.696us  32.385us  34.976us  void cuda::kernel::locate_features<float, int=9>\\n1.34%  91.713us      2  45.856us  45.792us  45.921us  void cuda::kernel::locate_features<double, int=9>\\n1.02%  69.505us      2  34.752us  34.400us  35.105us  void cuda::kernel::locate_features<unsigned int, int=9>\\n0.99%  67.456us      2  33.728us  32.768us  34.688us  void cuda::kernel::locate_features<int, int=9>\\n0.95%  65.186us      2  32.593us  31.201us  33.985us  void cuda::kernel::locate_features<short, int=9>\\n0.93%  63.874us      2  31.937us  30.817us  33.057us  void cuda::kernel::locate_features<unsigned short, int=9>\\n\\nPerformance using texture LUT\\n-----------------------------\\n\\nTime(%)    Time   Calls      Avg       Min       Max  Name\\n1.45%  99.776us      3  33.258us  32.896us  33.504us  void cuda::kernel::locate_features<float, int=9>\\n1.33%  91.105us      2  45.552us  44.961us  46.144us  void cuda::kernel::locate_features<double, int=9>\\n1.02%  70.017us      2  35.008us  34.273us  35.744us  void cuda::kernel::locate_features<unsigned int, int=9>\\n0.97%  66.689us      2  33.344us  32.065us  34.624us  void cuda::kernel::locate_features<int, int=9>\\n0.95%  65.249us      2  32.624us  31.585us  33.664us  void cuda::kernel::locate_features<short, int=9>\\n0.95%  65.025us      2  32.512us  30.945us  34.080us  void cuda::kernel::locate_features<unsigned short, int=9>',\n",
       "   'tree': {'sha': '54f4482ed4eed54b0832bbb58da50daa93a1f5aa',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/trees/54f4482ed4eed54b0832bbb58da50daa93a1f5aa'},\n",
       "   'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/commits/113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "  'html_url': 'https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "  'comments_url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/113cb18160a31d8ee04d11969bc57ff1628bda50/comments',\n",
       "  'author': {'login': '9prady9',\n",
       "   'id': 3270458,\n",
       "   'node_id': 'MDQ6VXNlcjMyNzA0NTg=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/3270458?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/9prady9',\n",
       "   'html_url': 'https://github.com/9prady9',\n",
       "   'followers_url': 'https://api.github.com/users/9prady9/followers',\n",
       "   'following_url': 'https://api.github.com/users/9prady9/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/9prady9/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/9prady9/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/9prady9/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/9prady9/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/9prady9/repos',\n",
       "   'events_url': 'https://api.github.com/users/9prady9/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/9prady9/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'umar456',\n",
       "   'id': 457510,\n",
       "   'node_id': 'MDQ6VXNlcjQ1NzUxMA==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/457510?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/umar456',\n",
       "   'html_url': 'https://github.com/umar456',\n",
       "   'followers_url': 'https://api.github.com/users/umar456/followers',\n",
       "   'following_url': 'https://api.github.com/users/umar456/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/umar456/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/umar456/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/umar456/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/umar456/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/umar456/repos',\n",
       "   'events_url': 'https://api.github.com/users/umar456/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/umar456/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': '06d767d4c0658d7af9e0fbec4ef32a03aa88f1a6',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/06d767d4c0658d7af9e0fbec4ef32a03aa88f1a6',\n",
       "    'html_url': 'https://github.com/arrayfire/arrayfire/commit/06d767d4c0658d7af9e0fbec4ef32a03aa88f1a6'}],\n",
       "  'stats': {'total': 138, 'additions': 113, 'deletions': 25},\n",
       "  'files': [{'sha': 'cc78ee73cdd7ccd52f051a4b171aef9e7e136dd6',\n",
       "    'filename': 'src/backend/cuda/CMakeLists.txt',\n",
       "    'status': 'modified',\n",
       "    'additions': 1,\n",
       "    'deletions': 0,\n",
       "    'changes': 1,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2FCMakeLists.txt',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2FCMakeLists.txt',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2FCMakeLists.txt?ref=113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'patch': '@@ -375,6 +375,7 @@ cuda_add_library(afcuda\\n \\n     Array.cpp\\n     Array.hpp\\n+    LookupTable1D.hpp\\n     Param.hpp\\n     anisotropic_diffusion.hpp\\n     approx.hpp'},\n",
       "   {'sha': '746607d5d53741159a5cd31532ab81ea294d13cf',\n",
       "    'filename': 'src/backend/cuda/LookupTable1D.hpp',\n",
       "    'status': 'added',\n",
       "    'additions': 66,\n",
       "    'deletions': 0,\n",
       "    'changes': 66,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2FLookupTable1D.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2FLookupTable1D.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2FLookupTable1D.hpp?ref=113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'patch': \"@@ -0,0 +1,66 @@\\n+/*******************************************************\\n+ * Copyright (c) 2020, ArrayFire\\n+ * All rights reserved.\\n+ *\\n+ * This file is distributed under 3-clause BSD license.\\n+ * The complete license agreement can be obtained at:\\n+ * http://arrayfire.com/licenses/BSD-3-Clause\\n+ ********************************************************/\\n+\\n+#pragma once\\n+\\n+#include <Array.hpp>\\n+#include <err_cuda.hpp>\\n+\\n+#include <type_traits>\\n+\\n+namespace cuda {\\n+\\n+template<typename T>\\n+class LookupTable1D {\\n+   public:\\n+    LookupTable1D()                          = delete;\\n+    LookupTable1D(const LookupTable1D& arg)  = delete;\\n+    LookupTable1D(const LookupTable1D&& arg) = delete;\\n+    LookupTable1D& operator=(const LookupTable1D& arg) = delete;\\n+    LookupTable1D& operator=(const LookupTable1D&& arg) = delete;\\n+\\n+    LookupTable1D(const Array<T>& lutArray) : mTexture(0), mData(lutArray) {\\n+        cudaResourceDesc resDesc;\\n+        memset(&resDesc, 0, sizeof(resDesc));\\n+\\n+        cudaTextureDesc texDesc;\\n+        memset(&texDesc, 0, sizeof(texDesc));\\n+\\n+        resDesc.resType                = cudaResourceTypeLinear;\\n+        resDesc.res.linear.devPtr      = mData.get();\\n+        resDesc.res.linear.desc.x      = sizeof(T) * 8;\\n+        resDesc.res.linear.sizeInBytes = mData.elements() * sizeof(T);\\n+\\n+        if (std::is_signed<T>::value)\\n+            resDesc.res.linear.desc.f = cudaChannelFormatKindSigned;\\n+        else if (std::is_unsigned<T>::value)\\n+            resDesc.res.linear.desc.f = cudaChannelFormatKindUnsigned;\\n+        else\\n+            resDesc.res.linear.desc.f = cudaChannelFormatKindFloat;\\n+\\n+        texDesc.readMode = cudaReadModeElementType;\\n+\\n+        CUDA_CHECK(\\n+            cudaCreateTextureObject(&mTexture, &resDesc, &texDesc, NULL));\\n+    }\\n+\\n+    ~LookupTable1D() {\\n+        if (mTexture) { cudaDestroyTextureObject(mTexture); }\\n+    }\\n+\\n+    cudaTextureObject_t get() const noexcept { return mTexture; }\\n+\\n+   private:\\n+    // Keep a copy so that ref count doesn't go down to zero when\\n+    // original Array<T> goes out of scope before LookupTable1D object does.\\n+    Array<T> mData;\\n+    cudaTextureObject_t mTexture;\\n+};\\n+\\n+}  // namespace cuda\"},\n",
       "   {'sha': 'd4f00274bc253dfe4dae33398c8a9679b5bd5e74',\n",
       "    'filename': 'src/backend/cuda/fast.cu',\n",
       "    'status': 'modified',\n",
       "    'additions': 13,\n",
       "    'deletions': 5,\n",
       "    'changes': 18,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Ffast.cu',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Ffast.cu',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Ffast.cu?ref=113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'patch': '@@ -7,11 +7,14 @@\\n  * http://arrayfire.com/licenses/BSD-3-Clause\\n  ********************************************************/\\n \\n-#include <Array.hpp>\\n-#include <err_cuda.hpp>\\n+#include <fast.hpp>\\n+\\n+#include <LookupTable1D.hpp>\\n #include <kernel/fast.hpp>\\n+#include <kernel/fast_lut.hpp>\\n #include <af/dim4.hpp>\\n-#include <af/features.h>\\n+\\n+#include <mutex>\\n \\n using af::dim4;\\n using af::features;\\n@@ -28,8 +31,14 @@ unsigned fast(Array<float> &x_out, Array<float> &y_out, Array<float> &score_out,\\n     float *d_y_out;\\n     float *d_score_out;\\n \\n+    // TODO(pradeep) Figure out a better way to create lut Array only once\\n+    const Array<unsigned char> lut = createHostDataArray(\\n+        af::dim4(sizeof(FAST_LUT) / sizeof(unsigned char)), FAST_LUT);\\n+\\n+    LookupTable1D<unsigned char> fastLUT(lut);\\n+\\n     kernel::fast<T>(&nfeat, &d_x_out, &d_y_out, &d_score_out, in, thr,\\n-                    arc_length, non_max, feature_ratio, edge);\\n+                    arc_length, non_max, feature_ratio, edge, fastLUT);\\n \\n     if (nfeat > 0) {\\n         const dim4 out_dims(nfeat);\\n@@ -38,7 +47,6 @@ unsigned fast(Array<float> &x_out, Array<float> &y_out, Array<float> &score_out,\\n         y_out     = createDeviceDataArray<float>(out_dims, d_y_out);\\n         score_out = createDeviceDataArray<float>(out_dims, d_score_out);\\n     }\\n-\\n     return nfeat;\\n }\\n '},\n",
       "   {'sha': 'e88722c7bc30cf9cd566cab09913accdb9ccff64',\n",
       "    'filename': 'src/backend/cuda/kernel/fast.hpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 31,\n",
       "    'deletions': 18,\n",
       "    'changes': 49,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Fkernel%2Ffast.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Fkernel%2Ffast.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Fkernel%2Ffast.hpp?ref=113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'patch': '@@ -9,14 +9,13 @@\\n \\n #pragma once\\n \\n+#include <LookupTable1D.hpp>\\n #include <common/dispatch.hpp>\\n #include <debug_cuda.hpp>\\n-#include <err_cuda.hpp>\\n-#include <kernel/fast_lut.hpp>\\n+#include <kernel/shared.hpp>\\n #include <math.hpp>\\n #include <memory.hpp>\\n #include <cub/block/block_reduce.cuh>\\n-#include \"shared.hpp\"\\n \\n namespace cuda {\\n namespace kernel {\\n@@ -102,11 +101,16 @@ inline __device__ double abs_diff(const double x, const double y) {\\n     return fabs(x - y);\\n }\\n \\n+inline __device__ int lookup(const int n, cudaTextureObject_t tex) {\\n+    return (int)tex1Dfetch<unsigned char>(tex, n);\\n+}\\n+\\n template<typename T, int arc_length>\\n __device__ void locate_features_core(T *local_image, float *score,\\n                                      const unsigned idim0, const unsigned idim1,\\n                                      const float thr, int x, int y,\\n-                                     const unsigned edge) {\\n+                                     const unsigned edge,\\n+                                     cudaTextureObject_t luTable) {\\n     if (x >= idim0 - edge || y >= idim1 - edge) return;\\n \\n     score[y * idim0 + x] = 0.f;\\n@@ -159,8 +163,8 @@ __device__ void locate_features_core(T *local_image, float *score,\\n \\n     // Checks LUT to verify if there is a segment for which all pixels are much\\n     // brighter or much darker than central pixel p.\\n-    if ((int)FAST_LUT[bright] >= arc_length ||\\n-        (int)FAST_LUT[dark] >= arc_length)\\n+    if (lookup(bright, luTable) >= arc_length ||\\n+        lookup(dark, luTable) >= arc_length)\\n         score[x + idim0 * y] = max_val(s_bright, s_dark);\\n }\\n \\n@@ -187,7 +191,8 @@ __device__ void load_shared_image(CParam<T> in, T *local_image, unsigned ix,\\n \\n template<typename T, int arc_length>\\n __global__ void locate_features(CParam<T> in, float *score, const float thr,\\n-                                const unsigned edge) {\\n+                                const unsigned edge,\\n+                                cudaTextureObject_t luTable) {\\n     unsigned ix = threadIdx.x;\\n     unsigned iy = threadIdx.y;\\n     unsigned bx = blockDim.x;\\n@@ -202,7 +207,7 @@ __global__ void locate_features(CParam<T> in, float *score, const float thr,\\n     load_shared_image(in, local_image_curr, ix, iy, bx, by, x, y, lx, ly, edge);\\n     __syncthreads();\\n     locate_features_core<T, arc_length>(local_image_curr, score, in.dims[0],\\n-                                        in.dims[1], thr, x, y, edge);\\n+                                        in.dims[1], thr, x, y, edge, luTable);\\n }\\n \\n template<bool nonmax>\\n@@ -316,8 +321,8 @@ __global__ void get_features(float *x_out, float *y_out, float *score_out,\\n template<typename T>\\n void fast(unsigned *out_feat, float **x_out, float **y_out, float **score_out,\\n           const Array<T> &in, const float thr, const unsigned arc_length,\\n-          const unsigned nonmax, const float feature_ratio,\\n-          const unsigned edge) {\\n+          const unsigned nonmax, const float feature_ratio, const unsigned edge,\\n+          const LookupTable1D<unsigned char> &luTable) {\\n     dim4 indims             = in.dims();\\n     const unsigned max_feat = ceil(indims[0] * indims[1] * feature_ratio);\\n \\n@@ -342,35 +347,43 @@ void fast(unsigned *out_feat, float **x_out, float **y_out, float **score_out,\\n     switch (arc_length) {\\n         case 9:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 9>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 10:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 10>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 11:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 11>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 12:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 12>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 13:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 13>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 14:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 14>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 15:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 15>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n         case 16:\\n             CUDA_LAUNCH_SMEM((locate_features<T, 16>), blocks, threads,\\n-                             shared_size, in, d_score.get(), thr, edge);\\n+                             shared_size, in, d_score.get(), thr, edge,\\n+                             luTable.get());\\n             break;\\n     }\\n '},\n",
       "   {'sha': '5ac82a67c7e9491843c6c8af2bfa23dff7b30ac0',\n",
       "    'filename': 'src/backend/cuda/kernel/fast_lut.hpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 2,\n",
       "    'deletions': 2,\n",
       "    'changes': 4,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Fkernel%2Ffast_lut.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/113cb18160a31d8ee04d11969bc57ff1628bda50/src%2Fbackend%2Fcuda%2Fkernel%2Ffast_lut.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Fkernel%2Ffast_lut.hpp?ref=113cb18160a31d8ee04d11969bc57ff1628bda50',\n",
       "    'patch': '@@ -1,5 +1,5 @@\\n /*******************************************************\\n- * Copyright (c) 2014, ArrayFire\\n+ * Copyright (c) 2020, ArrayFire\\n  * All rights reserved.\\n  *\\n  * This file is distributed under 3-clause BSD license.\\n@@ -9,7 +9,7 @@\\n \\n #pragma once\\n \\n-__constant__ unsigned char FAST_LUT[] = {\\n+unsigned char FAST_LUT[] = {\\n     0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n     0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\\n     0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,'}]},\n",
       " 'https://github.com/arrayfire/arrayfire/commit/46c66b5658beb84f4897581b16ae235f173ad97c': {'sha': '46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "  'node_id': 'MDY6Q29tbWl0MjU4ODk4MDI6NDZjNjZiNTY1OGJlYjg0ZjQ4OTc1ODFiMTZhZTIzNWYxNzNhZDk3Yw==',\n",
       "  'commit': {'author': {'name': 'Pradeep',\n",
       "    'email': 'pradeep@arrayfire.com',\n",
       "    'date': '2014-12-12T23:08:18Z'},\n",
       "   'committer': {'name': 'Pradeep',\n",
       "    'email': 'pradeep@arrayfire.com',\n",
       "    'date': '2014-12-12T23:08:18Z'},\n",
       "   'message': '2d convolve performance improvements\\n\\nchanged the shared memory loading access pattern in 2d convolve\\nkernel for cuda and opencl backends',\n",
       "   'tree': {'sha': '8b64a361102e7decf30673c01351ed00bbcf16d8',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/trees/8b64a361102e7decf30673c01351ed00bbcf16d8'},\n",
       "   'url': 'https://api.github.com/repos/arrayfire/arrayfire/git/commits/46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "  'html_url': 'https://github.com/arrayfire/arrayfire/commit/46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "  'comments_url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/46c66b5658beb84f4897581b16ae235f173ad97c/comments',\n",
       "  'author': {'login': '9prady9',\n",
       "   'id': 3270458,\n",
       "   'node_id': 'MDQ6VXNlcjMyNzA0NTg=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/3270458?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/9prady9',\n",
       "   'html_url': 'https://github.com/9prady9',\n",
       "   'followers_url': 'https://api.github.com/users/9prady9/followers',\n",
       "   'following_url': 'https://api.github.com/users/9prady9/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/9prady9/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/9prady9/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/9prady9/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/9prady9/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/9prady9/repos',\n",
       "   'events_url': 'https://api.github.com/users/9prady9/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/9prady9/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': '9prady9',\n",
       "   'id': 3270458,\n",
       "   'node_id': 'MDQ6VXNlcjMyNzA0NTg=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/3270458?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/9prady9',\n",
       "   'html_url': 'https://github.com/9prady9',\n",
       "   'followers_url': 'https://api.github.com/users/9prady9/followers',\n",
       "   'following_url': 'https://api.github.com/users/9prady9/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/9prady9/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/9prady9/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/9prady9/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/9prady9/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/9prady9/repos',\n",
       "   'events_url': 'https://api.github.com/users/9prady9/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/9prady9/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': 'a81805bb3fd1ec0923b6f0234e53145acc1e3f95',\n",
       "    'url': 'https://api.github.com/repos/arrayfire/arrayfire/commits/a81805bb3fd1ec0923b6f0234e53145acc1e3f95',\n",
       "    'html_url': 'https://github.com/arrayfire/arrayfire/commit/a81805bb3fd1ec0923b6f0234e53145acc1e3f95'}],\n",
       "  'stats': {'total': 146, 'additions': 66, 'deletions': 80},\n",
       "  'files': [{'sha': '514f9ec2f05c08507dd437c1ce3e639f254e6eab',\n",
       "    'filename': 'src/backend/cuda/kernel/convolve.hpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 44,\n",
       "    'deletions': 51,\n",
       "    'changes': 95,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/46c66b5658beb84f4897581b16ae235f173ad97c/src%2Fbackend%2Fcuda%2Fkernel%2Fconvolve.hpp',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/46c66b5658beb84f4897581b16ae235f173ad97c/src%2Fbackend%2Fcuda%2Fkernel%2Fconvolve.hpp',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fcuda%2Fkernel%2Fconvolve.hpp?ref=46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "    'patch': '@@ -39,7 +39,7 @@ static const dim_type MAX_CONV3_FILTER_LEN = 5;\\n \\n // we shall declare the maximum size required of above all three cases\\n // and re-use the same constant memory locations for every case\\n-__constant__ char cFilter[2*(2ll*(MAX_CONV1_FILTER_LEN-1ll)+THREADS)*sizeof(double)];\\n+__constant__ char cFilter[2*(2*(MAX_CONV1_FILTER_LEN-1)+THREADS)*sizeof(double)];\\n \\n __inline__ __device__\\n dim_type index(dim_type i, dim_type j, dim_type k, dim_type jstride, dim_type kstride)\\n@@ -60,6 +60,18 @@ T readSrc(T const *src, dim_type i, dim_type j, dim_type k, dim_type dims[], dim\\n         return scalar<T>(0);\\n }\\n \\n+template<typename T>\\n+__device__\\n+T readSrc(T const *src, dim_type i, dim_type j, dim_type dims[], dim_type strides[])\\n+{\\n+    bool is_i = i>=0 && i<dims[0];\\n+    bool is_j = j>=0 && j<dims[1];\\n+    if (is_i && is_j)\\n+        return src[i*strides[0] + j*strides[1]];\\n+    else\\n+        return scalar<T>(0);\\n+}\\n+\\n template<typename T, typename accType, bool expand>\\n __global__\\n void convolve1(Param<T> out, CParam<T> signal, dim_type fLen, dim_type nonBatchBlkSize,\\n@@ -85,7 +97,7 @@ void convolve1(Param<T> out, CParam<T> signal, dim_type fLen, dim_type nonBatchB\\n     }\\n     __syncthreads();\\n \\n-    if (gx>=0 && gx<out.dims[0]) {\\n+    if (gx<out.dims[0]) {\\n         dim_type lx   = threadIdx.x + padding + (expand ? 0 : fLen/2);\\n         accType accum = scalar<accType>(0);\\n         for(dim_type f=0; f<fLen; ++f) {\\n@@ -103,57 +115,50 @@ void convolve2(Param<T> out, CParam<T> signal, dim_type fLen0, dim_type fLen1,\\n     SharedMemory<T> shared;\\n \\n     T * shrdMem       = shared.getPointer();\\n-    dim_type pad0     = fLen0-1;\\n-    dim_type pad1     = fLen1-1;\\n-    dim_type shrdLen0 = blockDim.x + 2*pad0;\\n+    dim_type radius0  = fLen0-1;\\n+    dim_type radius1  = fLen1-1;\\n+    dim_type padding0 = 2*radius0;\\n+    dim_type padding1 = 2*radius1;\\n+    dim_type shrdLen0 = blockDim.x + padding0;\\n+\\n     unsigned batchId  = blockIdx.x/nonBatchBlkSize;\\n     T *dst            = (T *)out.ptr          + oStep + (batchId*out.strides[2]);\\n     const T *src      = (const T *)signal.ptr + sStep + (batchId*signal.strides[2]);\\n     const T *impulse  = (const T *)cFilter;\\n \\n-    dim_type lx = threadIdx.x;\\n-    dim_type ly = threadIdx.y;\\n-    dim_type gx = blockDim.x * (blockIdx.x-batchId*nonBatchBlkSize) + lx;\\n-    dim_type gy = blockDim.y * blockIdx.y + ly;\\n-    dim_type i = lx + pad0;\\n-    dim_type j = ly + pad1;\\n+    dim_type lx  = threadIdx.x;\\n+    dim_type ly  = threadIdx.y;\\n+    dim_type gx  = blockDim.x * (blockIdx.x-batchId*nonBatchBlkSize) + lx;\\n+    dim_type gy  = blockDim.y * blockIdx.y + ly;\\n \\n-    shrdMem[j*shrdLen0+i] = readSrc(src, gx, gy, 0, signal.dims, signal.strides);\\n+    dim_type lx2 = lx + blockDim.x;\\n+    dim_type ly2 = ly + blockDim.y;\\n+    dim_type gx2 = gx + blockDim.x;\\n+    dim_type gy2 = gy + blockDim.y;\\n \\n-    if (lx < pad0) {\\n-        dim_type gx2 = gx + blockDim.x;\\n-        dim_type lx2 = i  + blockDim.x;\\n-        shrdMem[j*shrdLen0+ lx] = readSrc(src, gx-pad0, gy, 0, signal.dims, signal.strides);\\n-        shrdMem[j*shrdLen0+lx2] = readSrc(src, gx2    , gy, 0, signal.dims, signal.strides);\\n+    shrdMem[ly*shrdLen0+lx] = readSrc(src, gx-radius0, gy-radius1, signal.dims, signal.strides);\\n+\\n+    if (lx < padding0) {\\n+        shrdMem[ly*shrdLen0+lx2] = readSrc(src, gx2-radius0, gy-radius1, signal.dims, signal.strides);\\n     }\\n-    if (ly < pad1) {\\n-        dim_type gy2 = gy + blockDim.y;\\n-        dim_type ly2 = j  + blockDim.y;\\n-        shrdMem[ly*shrdLen0 +i] = readSrc(src, gx, gy-pad1, 0, signal.dims, signal.strides);\\n-        shrdMem[ly2*shrdLen0+i] = readSrc(src, gx, gy2    , 0, signal.dims, signal.strides);\\n+    if (ly < padding1) {\\n+        shrdMem[ly2*shrdLen0+lx] = readSrc(src, gx-radius0, gy2-radius1, signal.dims, signal.strides);\\n     }\\n-    if (lx < pad0 && ly < pad1) {\\n-        dim_type gx2 = gx + blockDim.x;\\n-        dim_type lx2 = i  + blockDim.x;\\n-        dim_type gy2 = gy + blockDim.y;\\n-        dim_type ly2 = j  + blockDim.y;\\n-        // 4 corner regions\\n-        shrdMem[ly*shrdLen0+lx  ] = readSrc(src, gx-pad0, gy-pad1, 0, signal.dims, signal.strides);\\n-        shrdMem[ly*shrdLen0+lx2 ] = readSrc(src, gx2    , gy-pad1, 0, signal.dims, signal.strides);\\n-        shrdMem[ly2*shrdLen0+lx ] = readSrc(src, gx-pad0, gy2    , 0, signal.dims, signal.strides);\\n-        shrdMem[ly2*shrdLen0+lx2] = readSrc(src, gx2    , gy2    , 0, signal.dims, signal.strides);\\n+    if (lx < padding0 && ly < padding1) {\\n+        shrdMem[ly2*shrdLen0+lx2] = readSrc(src, gx2-radius0, gy2-radius1, signal.dims, signal.strides);\\n     }\\n+\\n     __syncthreads();\\n \\n-    if (gx>=0 && gx<out.dims[0] && gy>=0 && gy<out.dims[1]) {\\n-        dim_type ci = i + (expand ? 0 : fLen0/2);\\n-        dim_type cj = j + (expand ? 0 : fLen1/2);\\n+    if (gx<out.dims[0] && gy<out.dims[1]) {\\n+        dim_type ci = lx + radius0 + (expand ? 0 : fLen0/2);\\n+        dim_type cj = ly + radius1 + (expand ? 0 : fLen1/2);\\n \\n         accType accum = scalar<accType>(0);\\n         for(dim_type fj=0; fj<fLen1; ++fj) {\\n             for(dim_type fi=0; fi<fLen0; ++fi) {\\n                 T f_val = impulse[fj*fLen0+fi];\\n-                T s_val = shrdMem[(cj-fj)*shrdLen0+(ci-fi)];\\n+                T s_val = shrdMem[(cj-fj)*shrdLen0 + (ci-fi)];\\n                 accum   = accum + s_val*f_val;\\n             }\\n         }\\n@@ -247,7 +252,7 @@ void convolve3(Param<T> out, CParam<T> signal, dim_type fLen0, dim_type fLen1,\\n     }\\n     __syncthreads();\\n \\n-    if (gx>=0 && gx<out.dims[0] && gy>=0 && gy<out.dims[1] && gz>=0 && gz<out.dims[2]) {\\n+    if (gx<out.dims[0] && gy<out.dims[1] && gz<out.dims[2]) {\\n         dim_type ci = i + (expand ? 0 : fLen0/2);\\n         dim_type cj = j + (expand ? 0 : fLen1/2);\\n         dim_type ck = k + (expand ? 0 : fLen2/2);\\n@@ -302,8 +307,8 @@ void prepareKernelArgs(dim3 &blocks, dim3 &threads, size_t &sharedSize, dim_type\\n template<typename T, typename accType, dim_type baseDim, bool expand>\\n void convolve_nd(Param<T> out, CParam<T> signal, CParam<T> filter, ConvolveBatchKind kind)\\n {\\n-    dim_type bCount   = 1ll;\\n-    dim_type steps[3] = { 0ll, 0ll, 0ll };\\n+    dim_type bCount   = 1;\\n+    dim_type steps[3] = { 0, 0, 0 };\\n     // [0] - output step, [1] - signal step, [2] - filter step\\n     if (kind==MANY2MANY) {\\n         steps[0] = out.strides[baseDim];\\n@@ -350,18 +355,6 @@ void convolve_nd(Param<T> out, CParam<T> signal, CParam<T> filter, ConvolveBatch\\n     POST_LAUNCH_CHECK();\\n }\\n \\n-template<typename T>\\n-__device__\\n-T readSrc(T const *src, dim_type i, dim_type j, dim_type dims[], dim_type strides[])\\n-{\\n-    bool is_i = i>=0 && i<dims[0];\\n-    bool is_j = j>=0 && j<dims[1];\\n-    if (is_i && is_j)\\n-        return src[i*strides[0] + j*strides[1]];\\n-    else\\n-        return scalar<T>(0);\\n-}\\n-\\n template<typename T, typename accType, dim_type conv_dim, bool expand>\\n __global__\\n void convolve2_separable(Param<T> out, CParam<T> signal, dim_type fLen, dim_type nonBatchBlkSize)'},\n",
       "   {'sha': '0eaa87f67e2f15d6ae770554ceeaa9628c3a2794',\n",
       "    'filename': 'src/backend/opencl/kernel/convolve.cl',\n",
       "    'status': 'modified',\n",
       "    'additions': 22,\n",
       "    'deletions': 29,\n",
       "    'changes': 51,\n",
       "    'blob_url': 'https://github.com/arrayfire/arrayfire/blob/46c66b5658beb84f4897581b16ae235f173ad97c/src%2Fbackend%2Fopencl%2Fkernel%2Fconvolve.cl',\n",
       "    'raw_url': 'https://github.com/arrayfire/arrayfire/raw/46c66b5658beb84f4897581b16ae235f173ad97c/src%2Fbackend%2Fopencl%2Fkernel%2Fconvolve.cl',\n",
       "    'contents_url': 'https://api.github.com/repos/arrayfire/arrayfire/contents/src%2Fbackend%2Fopencl%2Fkernel%2Fconvolve.cl?ref=46c66b5658beb84f4897581b16ae235f173ad97c',\n",
       "    'patch': '@@ -68,9 +68,12 @@ void convolve(global T *out, KParam oInfo,\\n {\\n     dim_type fLen0    = fInfo.dims[0];\\n     dim_type fLen1    = fInfo.dims[1];\\n-    dim_type pad0     = fLen0-1;\\n-    dim_type pad1     = fLen1-1;\\n-    dim_type shrdLen0 = get_local_size(0) + 2*pad0;\\n+    dim_type radius0  = fLen0-1;\\n+    dim_type radius1  = fLen1-1;\\n+    dim_type padding0 = 2*radius0;\\n+    dim_type padding1 = 2*radius1;\\n+    dim_type shrdLen0 = get_local_size(0) + padding0;\\n+\\n     unsigned batchId  = get_group_id(0)/nonBatchBlkSize;\\n \\n     global T *dst = out + oStep +(batchId*oInfo.strides[2]);\\n@@ -80,39 +83,29 @@ void convolve(global T *out, KParam oInfo,\\n     dim_type ly = get_local_id(1);\\n     dim_type gx = get_local_size(0) * (get_group_id(0)-batchId*nonBatchBlkSize) + lx;\\n     dim_type gy = get_local_size(1) * get_group_id(1) + ly;\\n-    dim_type i = lx + pad0;\\n-    dim_type j = ly + pad1;\\n \\n-    localMem[j*shrdLen0+i] = readSrc(src, gx, gy, 0, sInfo.dims, sInfo.strides);\\n+    dim_type lx2= lx + get_local_size(0);\\n+    dim_type ly2= ly + get_local_size(1);\\n+    dim_type gx2= gx + get_local_size(0);\\n+    dim_type gy2= gy + get_local_size(1);\\n \\n-    if (lx < pad0) {\\n-        dim_type gx2 = gx + get_local_size(0);\\n-        dim_type lx2 = i  + get_local_size(0);\\n-        localMem[j*shrdLen0+ lx] = readSrc(src, gx-pad0, gy, 0, sInfo.dims, sInfo.strides);\\n-        localMem[j*shrdLen0+lx2] = readSrc(src, gx2    , gy, 0, sInfo.dims, sInfo.strides);\\n+    localMem[ly*shrdLen0+lx] = readSrc(src, gx-radius0, gy-radius1, 0, sInfo.dims, sInfo.strides);\\n+\\n+    if (lx < padding0) {\\n+        localMem[ly*shrdLen0+lx2] = readSrc(src, gx2-radius0, gy-radius1, 0, sInfo.dims, sInfo.strides);\\n     }\\n-    if (ly < pad1) {\\n-        dim_type gy2 = gy + get_local_size(1);\\n-        dim_type ly2 = j  + get_local_size(1);\\n-        localMem[ly*shrdLen0 +i] = readSrc(src, gx, gy-pad1, 0, sInfo.dims, sInfo.strides);\\n-        localMem[ly2*shrdLen0+i] = readSrc(src, gx, gy2    , 0, sInfo.dims, sInfo.strides);\\n+    if (ly < padding1) {\\n+        localMem[ly2*shrdLen0+lx] = readSrc(src, gx-radius0, gy2-radius1, 0, sInfo.dims, sInfo.strides);\\n     }\\n-    if (lx < pad0 && ly < pad1) {\\n-        dim_type gx2 = gx + get_local_size(0);\\n-        dim_type lx2 = i  + get_local_size(0);\\n-        dim_type gy2 = gy + get_local_size(1);\\n-        dim_type ly2 = j  + get_local_size(1);\\n-        // 4 corner regions\\n-        localMem[ly*shrdLen0+lx  ] = readSrc(src, gx-pad0, gy-pad1, 0, sInfo.dims, sInfo.strides);\\n-        localMem[ly*shrdLen0+lx2 ] = readSrc(src, gx2    , gy-pad1, 0, sInfo.dims, sInfo.strides);\\n-        localMem[ly2*shrdLen0+lx ] = readSrc(src, gx-pad0, gy2    , 0, sInfo.dims, sInfo.strides);\\n-        localMem[ly2*shrdLen0+lx2] = readSrc(src, gx2    , gy2    , 0, sInfo.dims, sInfo.strides);\\n+    if (lx < padding0 && ly < padding1) {\\n+        localMem[ly2*shrdLen0+lx2] = readSrc(src, gx2-radius0, gy2-radius1, 0, sInfo.dims, sInfo.strides);\\n     }\\n+\\n     barrier(CLK_LOCAL_MEM_FENCE);\\n \\n-    if (gx>=0 && gx<oInfo.dims[0] && gy>=0 && gy<oInfo.dims[1]) {\\n-        dim_type ci = i + (EXPAND ? 0 : fLen0/2);\\n-        dim_type cj = j + (EXPAND ? 0 : fLen1/2);\\n+    if (gx<oInfo.dims[0] && gy<oInfo.dims[1]) {\\n+        dim_type ci = lx + radius0 + (EXPAND ? 0 : fLen0/2);\\n+        dim_type cj = ly + radius1 + (EXPAND ? 0 : fLen1/2);\\n \\n         accType accum = (accType)(0);\\n         for(dim_type fj=0; fj<fLen1; ++fj) {'}]},\n",
       " 'https://github.com/openmm/openmm/commit/926e7b9ac11a8614f310b59a2d786788771ccb5b': {'sha': '926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "  'node_id': 'MDY6Q29tbWl0MTAxNzgxODg6OTI2ZTdiOWFjMTFhODYxNGYzMTBiNTlhMmQ3ODY3ODg3NzFjY2I1Yg==',\n",
       "  'commit': {'author': {'name': 'Michael Schnieders',\n",
       "    'email': 'michael-schnieders@uiowa.edu',\n",
       "    'date': '2019-08-22T19:16:18Z'},\n",
       "   'committer': {'name': 'Michael Schnieders',\n",
       "    'email': 'michael-schnieders@uiowa.edu',\n",
       "    'date': '2019-08-22T19:16:18Z'},\n",
       "   'message': 'Improve the performance of sending the AmoebaVdwLambda to Cuda using pinned host memory; Updated the AmoebaVdwForceProxy to version 3, and added backward compatibility to version 2; updated TestAPIUnits.py to handle the per particle lambda flag',\n",
       "   'tree': {'sha': '4bf37942c2dbd4ab1b27f2399694b86f01048df2',\n",
       "    'url': 'https://api.github.com/repos/openmm/openmm/git/trees/4bf37942c2dbd4ab1b27f2399694b86f01048df2'},\n",
       "   'url': 'https://api.github.com/repos/openmm/openmm/git/commits/926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "   'comment_count': 0,\n",
       "   'verification': {'verified': False,\n",
       "    'reason': 'unsigned',\n",
       "    'signature': None,\n",
       "    'payload': None}},\n",
       "  'url': 'https://api.github.com/repos/openmm/openmm/commits/926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "  'html_url': 'https://github.com/openmm/openmm/commit/926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "  'comments_url': 'https://api.github.com/repos/openmm/openmm/commits/926e7b9ac11a8614f310b59a2d786788771ccb5b/comments',\n",
       "  'author': {'login': 'mjschnie',\n",
       "   'id': 8150984,\n",
       "   'node_id': 'MDQ6VXNlcjgxNTA5ODQ=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/8150984?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/mjschnie',\n",
       "   'html_url': 'https://github.com/mjschnie',\n",
       "   'followers_url': 'https://api.github.com/users/mjschnie/followers',\n",
       "   'following_url': 'https://api.github.com/users/mjschnie/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/mjschnie/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/mjschnie/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/mjschnie/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/mjschnie/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/mjschnie/repos',\n",
       "   'events_url': 'https://api.github.com/users/mjschnie/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/mjschnie/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'committer': {'login': 'mjschnie',\n",
       "   'id': 8150984,\n",
       "   'node_id': 'MDQ6VXNlcjgxNTA5ODQ=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/8150984?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/mjschnie',\n",
       "   'html_url': 'https://github.com/mjschnie',\n",
       "   'followers_url': 'https://api.github.com/users/mjschnie/followers',\n",
       "   'following_url': 'https://api.github.com/users/mjschnie/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/mjschnie/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/mjschnie/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/mjschnie/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/mjschnie/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/mjschnie/repos',\n",
       "   'events_url': 'https://api.github.com/users/mjschnie/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/mjschnie/received_events',\n",
       "   'type': 'User',\n",
       "   'site_admin': False},\n",
       "  'parents': [{'sha': '9c95f25c7cf78f834ff296591b8d716dce838cf1',\n",
       "    'url': 'https://api.github.com/repos/openmm/openmm/commits/9c95f25c7cf78f834ff296591b8d716dce838cf1',\n",
       "    'html_url': 'https://github.com/openmm/openmm/commit/9c95f25c7cf78f834ff296591b8d716dce838cf1'}],\n",
       "  'stats': {'total': 106, 'additions': 76, 'deletions': 30},\n",
       "  'files': [{'sha': 'bf4be5911fe9b1eb329254e2ec6b8177454f29f0',\n",
       "    'filename': 'plugins/amoeba/openmmapi/include/openmm/AmoebaVdwForce.h',\n",
       "    'status': 'modified',\n",
       "    'additions': 13,\n",
       "    'deletions': 0,\n",
       "    'changes': 13,\n",
       "    'blob_url': 'https://github.com/openmm/openmm/blob/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fopenmmapi%2Finclude%2Fopenmm%2FAmoebaVdwForce.h',\n",
       "    'raw_url': 'https://github.com/openmm/openmm/raw/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fopenmmapi%2Finclude%2Fopenmm%2FAmoebaVdwForce.h',\n",
       "    'contents_url': 'https://api.github.com/repos/openmm/openmm/contents/plugins%2Famoeba%2Fopenmmapi%2Finclude%2Fopenmm%2FAmoebaVdwForce.h?ref=926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "    'patch': '@@ -50,6 +50,19 @@ namespace OpenMM {\\n  * particle to another one.  This is typically done for hydrogens to place the interaction site slightly\\n  * closer to the parent atom.  The fraction is known as the \"reduction factor\", since it reduces the distance\\n  * from the parent atom to the interaction site.\\n+ *\\n+ * Support is also available for softcore interactions based on setting a per particle alchemical flag and\\n+ * setting the AmoebaVdwForce to use an \"AlchemicalMethod\" -- either Decouple or Annihilate.\\n+ * For Decouple, two alchemical atoms interact normally. For Annihilate, all interactions involving an \\n+ * alchemical atom are influenced. The softcore state is specified by setting a single \\n+ * Context parameter \"AmoebaVdwLambda\" between 0.0 and 1.0.\\n+ *\\n+ * The softcore functional form can be modified by setting the softcore power (default of 5) and the softcore\\n+ * alpha (default of 0,7). For more information on the softcore functional form see Eq. 2 from:\\n+ * Jiao, D.;  Golubkov, P. A.;  Darden, T. A.; Ren, P., \\n+ * Calculation of protein-ligand binding free energy by using a polarizable potential.\\n+ * Proc. Natl. Acad. Sci. U.S.A. 2008, 105 (17), 6290-6295.\\n+ * https://www.pnas.org/content/105/17/6290.\\n  */\\n \\n class OPENMM_EXPORT_AMOEBA AmoebaVdwForce : public Force {'},\n",
       "   {'sha': '5ea6ea70507121e36b1e054dbdc436f476a74745',\n",
       "    'filename': 'plugins/amoeba/platforms/cuda/src/AmoebaCudaKernels.cpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 33,\n",
       "    'deletions': 19,\n",
       "    'changes': 52,\n",
       "    'blob_url': 'https://github.com/openmm/openmm/blob/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.cpp',\n",
       "    'raw_url': 'https://github.com/openmm/openmm/raw/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.cpp',\n",
       "    'contents_url': 'https://api.github.com/repos/openmm/openmm/contents/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.cpp?ref=926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "    'patch': '@@ -2353,32 +2353,40 @@ class CudaCalcAmoebaVdwForceKernel::ForceInfo : public CudaForceInfo {\\n };\\n \\n CudaCalcAmoebaVdwForceKernel::CudaCalcAmoebaVdwForceKernel(std::string name, const Platform& platform, CudaContext& cu, const System& system) :\\n-        CalcAmoebaVdwForceKernel(name, platform), cu(cu), system(system), hasInitializedNonbonded(false), nonbonded(NULL) {\\n+        CalcAmoebaVdwForceKernel(name, platform), cu(cu), system(system), hasInitializedNonbonded(false), nonbonded(NULL), vdwLambdaPinnedBuffer(NULL) {\\n }\\n \\n CudaCalcAmoebaVdwForceKernel::~CudaCalcAmoebaVdwForceKernel() {\\n     cu.setAsCurrent();\\n     if (nonbonded != NULL)\\n         delete nonbonded;\\n+    if (vdwLambdaPinnedBuffer != NULL) \\n+        cuMemFreeHost(vdwLambdaPinnedBuffer);                              \\n }\\n \\n void CudaCalcAmoebaVdwForceKernel::initialize(const System& system, const AmoebaVdwForce& force) {\\n     cu.setAsCurrent();\\n     sigmaEpsilon.initialize<float2>(cu, cu.getPaddedNumAtoms(), \"sigmaEpsilon\");\\n-    isAlchemical.initialize<float>(cu, cu.getPaddedNumAtoms(), \"isAlchemical\");\\n-    vdwLambda.initialize<float>(cu, 1, \"vdwLambda\");\\n     bondReductionAtoms.initialize<int>(cu, cu.getPaddedNumAtoms(), \"bondReductionAtoms\");\\n     bondReductionFactors.initialize<float>(cu, cu.getPaddedNumAtoms(), \"bondReductionFactors\");\\n     tempPosq.initialize(cu, cu.getPaddedNumAtoms(), cu.getUseDoublePrecision() ? sizeof(double4) : sizeof(float4), \"tempPosq\");\\n     tempForces.initialize<long long>(cu, 3*cu.getPaddedNumAtoms(), \"tempForces\");\\n     \\n     // Record atom parameters.\\n-    \\n     vector<float2> sigmaEpsilonVec(cu.getPaddedNumAtoms(), make_float2(0, 1));\\n     vector<float> isAlchemicalVec(cu.getPaddedNumAtoms(), 0);\\n     vector<int> bondReductionAtomsVec(cu.getPaddedNumAtoms(), 0);\\n     vector<float> bondReductionFactorsVec(cu.getPaddedNumAtoms(), 0);\\n     vector<vector<int> > exclusions(cu.getNumAtoms());\\n+\\n+    // Handle Alchemical parameters.\\n+    hasAlchemical = force.getAlchemicalMethod() != AmoebaVdwForce::None;\\n+    if (hasAlchemical) {\\n+       isAlchemical.initialize<float>(cu, cu.getPaddedNumAtoms(), \"isAlchemical\");\\n+       vdwLambda.initialize<float>(cu, 1, \"vdwLambda\");\\n+       CHECK_RESULT(cuMemHostAlloc(&vdwLambdaPinnedBuffer, sizeof(float), 0), \"Error allocating vdwLambda pinned buffer\");\\n+    }\\n+\\n     for (int i = 0; i < force.getNumParticles(); i++) {\\n         int ivIndex;\\n         double sigma, epsilon, reductionFactor;\\n@@ -2392,27 +2400,28 @@ void CudaCalcAmoebaVdwForceKernel::initialize(const System& system, const Amoeba\\n         exclusions[i].push_back(i);\\n     }\\n     sigmaEpsilon.upload(sigmaEpsilonVec);\\n-    isAlchemical.upload(isAlchemicalVec);\\n     bondReductionAtoms.upload(bondReductionAtomsVec);\\n     bondReductionFactors.upload(bondReductionFactorsVec);\\n     if (force.getUseDispersionCorrection())\\n         dispersionCoefficient = AmoebaVdwForceImpl::calcDispersionCorrection(system, force);\\n     else\\n         dispersionCoefficient = 0.0;               \\n \\n-    // A single lambda parameter to define the alchemical vdW state.\\n-    vector<float> vdwLambdaVec(1, 0);\\n-    vdwLambdaVec[0] = 1.0f;\\n-    vdwLambda.upload(vdwLambdaVec);\\n- \\n     // This force is applied based on modified atom positions, where hydrogens have been moved slightly\\n     // closer to their parent atoms.  We therefore create a separate CudaNonbondedUtilities just for\\n     // this force, so it will have its own neighbor list and interaction kernel.\\n     \\n     nonbonded = new CudaNonbondedUtilities(cu);\\n     nonbonded->addParameter(CudaNonbondedUtilities::ParameterInfo(\"sigmaEpsilon\", \"float\", 2, sizeof(float2), sigmaEpsilon.getDevicePointer()));\\n-    nonbonded->addParameter(CudaNonbondedUtilities::ParameterInfo(\"isAlchemical\", \"float\", 1, sizeof(float), isAlchemical.getDevicePointer()));\\n-    nonbonded->addArgument(CudaNonbondedUtilities::ParameterInfo(\"vdwLambda\", \"float\", 1, sizeof(float), vdwLambda.getDevicePointer()));\\n+\\n+    if (hasAlchemical) {\\n+       isAlchemical.upload(isAlchemicalVec);\\n+       ((float*) vdwLambdaPinnedBuffer)[0] = 1.0f;\\n+       currentVdwLambda = 1.0f;\\n+       vdwLambda.upload(vdwLambdaPinnedBuffer, false);\\n+       nonbonded->addParameter(CudaNonbondedUtilities::ParameterInfo(\"isAlchemical\", \"float\", 1, sizeof(float), isAlchemical.getDevicePointer()));\\n+       nonbonded->addArgument(CudaNonbondedUtilities::ParameterInfo(\"vdwLambda\", \"float\", 1, sizeof(float), vdwLambda.getDevicePointer()));\\n+    }\\n     \\n     // Create the interaction kernel.\\n     \\n@@ -2431,16 +2440,16 @@ void CudaCalcAmoebaVdwForceKernel::initialize(const System& system, const Amoeba\\n         replacements[\"EPSILON_COMBINING_RULE\"] = \"1\";\\n     else if (epsilonCombiningRule == \"GEOMETRIC\")\\n         replacements[\"EPSILON_COMBINING_RULE\"] = \"2\";\\n-    else if (epsilonCombiningRule == \"HARMONIC\")\\n+    else if (epsilonCombiningRule ==\"HARMONIC\")\\n         replacements[\"EPSILON_COMBINING_RULE\"] = \"3\";\\n     else if (epsilonCombiningRule == \"HHG\")\\n         replacements[\"EPSILON_COMBINING_RULE\"] = \"4\";\\n     else\\n         throw OpenMMException(\"Illegal combining rule for sigma: \"+sigmaCombiningRule);\\n \\n+    replacements[\"VDW_ALCHEMICAL_METHOD\"] = cu.intToString(force.getAlchemicalMethod()); \\n     replacements[\"VDW_SOFTCORE_POWER\"] = cu.intToString(force.getSoftcorePower());\\n     replacements[\"VDW_SOFTCORE_ALPHA\"] = cu.doubleToString(force.getSoftcoreAlpha()); \\n-    replacements[\"VDW_ALCHEMICAL_METHOD\"] = cu.intToString(force.getAlchemicalMethod()); \\n \\n     double cutoff = force.getCutoffDistance();\\n     double taperCutoff = cutoff*0.9;\\n@@ -2469,10 +2478,15 @@ double CudaCalcAmoebaVdwForceKernel::execute(ContextImpl& context, bool includeF\\n         nonbonded->initialize(system);\\n     }\\n \\n-    // Not sure about passing a Context parameter to the Kernal?\\n-    vector<float> vdwLambdaVec(1, 0);\\n-    vdwLambdaVec[0] = context.getParameter(AmoebaVdwForce::Lambda());\\n-    vdwLambda.upload(vdwLambdaVec);\\n+    if (hasAlchemical) {\\n+       float contextLambda = context.getParameter(AmoebaVdwForce::Lambda());\\n+       if (contextLambda != currentVdwLambda) {\\n+          // Non-blocking copy of vdwLambda to device memory\\n+          ((float*) vdwLambdaPinnedBuffer)[0] = contextLambda;\\n+          vdwLambda.upload(vdwLambdaPinnedBuffer, false);\\n+          currentVdwLambda = contextLambda;\\n+       }\\n+    }\\n \\n     cu.getPosq().copyTo(tempPosq);\\n     cu.getForce().copyTo(tempForces);\\n@@ -2512,7 +2526,7 @@ void CudaCalcAmoebaVdwForceKernel::copyParametersToContext(ContextImpl& context,\\n         bondReductionFactorsVec[i] = (float) reductionFactor;\\n     }\\n     sigmaEpsilon.upload(sigmaEpsilonVec);\\n-    isAlchemical.upload(isAlchemicalVec);\\n+    if (hasAlchemical) isAlchemical.upload(isAlchemicalVec);\\n     bondReductionAtoms.upload(bondReductionAtomsVec);\\n     bondReductionFactors.upload(bondReductionFactorsVec);\\n     if (force.getUseDispersionCorrection())'},\n",
       "   {'sha': '9ab7a03f5a2062780066673016b537c45d9c064d',\n",
       "    'filename': 'plugins/amoeba/platforms/cuda/src/AmoebaCudaKernels.h',\n",
       "    'status': 'modified',\n",
       "    'additions': 12,\n",
       "    'deletions': 2,\n",
       "    'changes': 14,\n",
       "    'blob_url': 'https://github.com/openmm/openmm/blob/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.h',\n",
       "    'raw_url': 'https://github.com/openmm/openmm/raw/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.h',\n",
       "    'contents_url': 'https://api.github.com/repos/openmm/openmm/contents/plugins%2Famoeba%2Fplatforms%2Fcuda%2Fsrc%2FAmoebaCudaKernels.h?ref=926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "    'patch': '@@ -571,12 +571,22 @@ class CudaCalcAmoebaVdwForceKernel : public CalcAmoebaVdwForceKernel {\\n     CudaContext& cu;\\n     const System& system;\\n     bool hasInitializedNonbonded;\\n+\\n+    // True if the AmoebaVdwForce AlchemicalMethod is not None.\\n+    bool hasAlchemical;\\n+    // Pinned host memory; allocated if necessary in initialize, and freed in the destructor.\\n+    void* vdwLambdaPinnedBuffer;\\n+    // Device memory for the alchemical state.\\n+    CudaArray vdwLambda;\\n+    // Only update device memory when lambda changes.\\n+    float currentVdwLambda;\\n+    // Per particle alchemical flag.\\n+    CudaArray isAlchemical;\\n+\\n     double dispersionCoefficient;\\n     CudaArray sigmaEpsilon;\\n     CudaArray bondReductionAtoms;\\n     CudaArray bondReductionFactors;\\n-    CudaArray isAlchemical;\\n-    CudaArray vdwLambda;\\n     CudaArray tempPosq;\\n     CudaArray tempForces;\\n     CudaNonbondedUtilities* nonbonded;'},\n",
       "   {'sha': 'd51daab3496ce1b7cf4bab4078e289965c5132f0',\n",
       "    'filename': 'plugins/amoeba/serialization/src/AmoebaVdwForceProxy.cpp',\n",
       "    'status': 'modified',\n",
       "    'additions': 15,\n",
       "    'deletions': 6,\n",
       "    'changes': 21,\n",
       "    'blob_url': 'https://github.com/openmm/openmm/blob/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fserialization%2Fsrc%2FAmoebaVdwForceProxy.cpp',\n",
       "    'raw_url': 'https://github.com/openmm/openmm/raw/926e7b9ac11a8614f310b59a2d786788771ccb5b/plugins%2Famoeba%2Fserialization%2Fsrc%2FAmoebaVdwForceProxy.cpp',\n",
       "    'contents_url': 'https://api.github.com/repos/openmm/openmm/contents/plugins%2Famoeba%2Fserialization%2Fsrc%2FAmoebaVdwForceProxy.cpp?ref=926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "    'patch': '@@ -42,7 +42,7 @@ AmoebaVdwForceProxy::AmoebaVdwForceProxy() : SerializationProxy(\"AmoebaVdwForce\"\\n }\\n \\n void AmoebaVdwForceProxy::serialize(const void* object, SerializationNode& node) const {\\n-    node.setIntProperty(\"version\", 2);\\n+    node.setIntProperty(\"version\", 3);\\n     const AmoebaVdwForce& force = *reinterpret_cast<const AmoebaVdwForce*>(object);\\n \\n     node.setIntProperty(\"forceGroup\", force.getForceGroup());\\n@@ -78,7 +78,7 @@ void AmoebaVdwForceProxy::serialize(const void* object, SerializationNode& node)\\n \\n void* AmoebaVdwForceProxy::deserialize(const SerializationNode& node) const {\\n     int version = node.getIntProperty(\"version\");\\n-    if (version < 1 || version > 2)\\n+    if (version < 1 || version > 3)\\n         throw OpenMMException(\"Unsupported version number\");\\n     AmoebaVdwForce* force = new AmoebaVdwForce();\\n     try {\\n@@ -89,14 +89,23 @@ void* AmoebaVdwForceProxy::deserialize(const SerializationNode& node) const {\\n         force->setCutoffDistance(node.getDoubleProperty(\"VdwCutoff\"));\\n         force->setNonbondedMethod((AmoebaVdwForce::NonbondedMethod) node.getIntProperty(\"method\"));\\n \\n-        force->setAlchemicalMethod((AmoebaVdwForce::AlchemicalMethod) node.getIntProperty(\"alchemicalMethod\"));\\n-        force->setSoftcorePower(node.getDoubleProperty(\"n\"));\\n-        force->setSoftcoreAlpha(node.getDoubleProperty(\"alpha\"));\\n+        if (version > 2) {\\n+           force->setAlchemicalMethod((AmoebaVdwForce::AlchemicalMethod) node.getIntProperty(\"alchemicalMethod\"));\\n+           force->setSoftcorePower(node.getDoubleProperty(\"n\"));\\n+           force->setSoftcoreAlpha(node.getDoubleProperty(\"alpha\"));\\n+        }\\n \\n         const SerializationNode& particles = node.getChildNode(\"VdwParticles\");\\n         for (unsigned int ii = 0; ii < particles.getChildren().size(); ii++) {\\n             const SerializationNode& particle = particles.getChildren()[ii];\\n-            force->addParticle(particle.getIntProperty(\"ivIndex\"), particle.getDoubleProperty(\"sigma\"), particle.getDoubleProperty(\"epsilon\"), particle.getDoubleProperty(\"reductionFactor\"), particle.getBoolProperty(\"isAlchemical\"));\\n+\\n+            if (version < 3) \\n+               force->addParticle(particle.getIntProperty(\"ivIndex\"), particle.getDoubleProperty(\"sigma\"), \\n+                                  particle.getDoubleProperty(\"epsilon\"), particle.getDoubleProperty(\"reductionFactor\"));\\n+            else \\n+               force->addParticle(particle.getIntProperty(\"ivIndex\"), particle.getDoubleProperty(\"sigma\"), \\n+                                  particle.getDoubleProperty(\"epsilon\"), particle.getDoubleProperty(\"reductionFactor\"), \\n+                                  particle.getBoolProperty(\"isAlchemical\"));\\n \\n             // exclusions\\n '},\n",
       "   {'sha': '2e371361aee45d4e066f2ea5480694e8b1054c46',\n",
       "    'filename': 'wrappers/python/tests/TestAPIUnits.py',\n",
       "    'status': 'modified',\n",
       "    'additions': 3,\n",
       "    'deletions': 3,\n",
       "    'changes': 6,\n",
       "    'blob_url': 'https://github.com/openmm/openmm/blob/926e7b9ac11a8614f310b59a2d786788771ccb5b/wrappers%2Fpython%2Ftests%2FTestAPIUnits.py',\n",
       "    'raw_url': 'https://github.com/openmm/openmm/raw/926e7b9ac11a8614f310b59a2d786788771ccb5b/wrappers%2Fpython%2Ftests%2FTestAPIUnits.py',\n",
       "    'contents_url': 'https://api.github.com/repos/openmm/openmm/contents/wrappers%2Fpython%2Ftests%2FTestAPIUnits.py?ref=926e7b9ac11a8614f310b59a2d786788771ccb5b',\n",
       "    'patch': '@@ -969,23 +969,23 @@ def testAmoebaVdwForce(self):\\n \\n         self.assertEqual(force.getNumParticles(), 3)\\n \\n-        p, sig, eps, scale = force.getParticleParameters(0)\\n+        p, sig, eps, scale, alchemical = force.getParticleParameters(0)\\n         self.assertEqual(p, 0)\\n         self.assertEqual(sig, 0.1*nanometers)\\n         self.assertIs(sig.unit, nanometers)\\n         self.assertEqual(eps, 1.0*kilojoules_per_mole)\\n         self.assertIs(eps.unit, kilojoules_per_mole)\\n         self.assertEqual(scale, 1.0)\\n \\n-        p, sig, eps, scale = force.getParticleParameters(1)\\n+        p, sig, eps, scale, alchemical = force.getParticleParameters(1)\\n         self.assertEqual(p, 1)\\n         self.assertEqual(sig, 1.0*angstroms)\\n         self.assertIs(sig.unit, nanometers)\\n         self.assertEqual(eps, 1.0*kilocalories_per_mole)\\n         self.assertIs(eps.unit, kilojoules_per_mole)\\n         self.assertEqual(scale, 0.5)\\n \\n-        p, sig, eps, scale = force.getParticleParameters(2)\\n+        p, sig, eps, scale, alchemical = force.getParticleParameters(2)\\n         self.assertEqual(p, 1)\\n         self.assertAlmostEqualUnit(sig, 0.8*angstroms)\\n         self.assertIs(sig.unit, nanometers)'}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "path=\".\\\\Data\\\\RQ1\\\\RQ1.xlsx\"\n",
    "listt=[]\n",
    "actualList=[]\n",
    "ownerList=[]\n",
    "ProjectList=[]\n",
    "HashList=[]\n",
    "df = pd.read_excel(path)\n",
    "#print(df.iloc[:,17])\n",
    "\n",
    "#for all rows\n",
    "#listt.append(df.iloc[:,17])\n",
    "\n",
    "#for cuda links only\n",
    "listt.append(df[df.iloc[:, 17].isin(git_links)].iloc[:, 17])\n",
    "\n",
    "for i in listt[0]:\n",
    "    actualList.append(i)\n",
    "actualList.pop()\n",
    "for i in actualList:\n",
    "    text=i[19:]\n",
    "    splittedVer=text.split('/')\n",
    "    ownerList.append(splittedVer[0])\n",
    "    ProjectList.append(splittedVer[1])\n",
    "    HashList.append(splittedVer[3])\n",
    "    \n",
    "headers = {    \n",
    "    \"Authorization\": f\"token {github_key}\"\n",
    "}\n",
    "all_git_responses={}\n",
    "false = False\n",
    "null = None\n",
    "#pickled this list\n",
    "\n",
    "def get_git_response(owner, repo, commit_sha, link):\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/commits/{commit_sha}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return (link, dict(response.json()))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for owner, repo, commit_sha, link in zip(ownerList, ProjectList, HashList, actualList):\n",
    "        futures.append(executor.submit(get_git_response, owner, repo, commit_sha, link))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        link, response = future.result()\n",
    "        all_git_responses[link] = response\n",
    "\n",
    "with open(\"./pickles/git_respos.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_git_responses, f)\n",
    "\n",
    "with open(\"./pickles/git_respos.pkl\", \"rb\") as f:\n",
    "    all_git_responses = pickle.load(f)\n",
    "\n",
    "all_git_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_in_a_comit={}\n",
    "for repo in all_git_responses:\n",
    "    all_files_in_a_comit[repo]=all_git_responses[repo][\"files\"]\n",
    "\n",
    "all_patches_in_all_files_in_a_comit ={}\n",
    "for repo in all_files_in_a_comit:\n",
    "    all_patches_in_all_files_in_a_comit[repo]=[]\n",
    "    for file in all_files_in_a_comit[repo]:\n",
    "        all_patches_in_all_files_in_a_comit[repo].append( remove_unimportant_spaces( parse_patch( file[\"patch\"]) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/openmm/openmm/commit/926e7b9ac11a8614f310b59a2d786788771ccb5b': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/ginkgo-project/ginkgo/commit/154aafbd57e93e4ede30b1566d2bf03e7c1b096e': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/arrayfire/arrayfire/commit/d8d8c439c8d0a43c0f92b11fd06133be80754ab8': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/gromacs/gromacs/commit/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/gromacs/gromacs/commit/8aa14d11ff775055794360a655fe800deea298a8': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/lattice/quda/commit/0dd4f75396999b649c759946fe0b53e6cd12aae0': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"], 'https://github.com/arrayfire/arrayfire/commit/46c66b5658beb84f4897581b16ae235f173ad97c': ['Inefficient memory management.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficient memory management.', 'Unintentional Programming logic error', 'Missing parallelism', 'Inefficient algorithm /data-structure and their implementation.', 'Missing parallelism.', 'Missing parallelism.', 'Inefficiency due to new compiler version.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture.', 'Missing parallelism.', 'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).', 'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)', 'Missing parallelism', 'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.', 'Missing parallelism', \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\", 'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.', 'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.', \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"]}\n"
     ]
    }
   ],
   "source": [
    "all_responses_in_all_files_in_a_comit = {}\n",
    "\n",
    "def categorize_patch(patch):\n",
    "    try: \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_promt},\n",
    "                {\"role\": \"user\", \"content\": f\"Please categorize the following patches into single one of the listed categories ? {patch}  ?  \"} ,       \n",
    "            ],  \n",
    "        )            \n",
    "        return response['choices'][0]['message'][\"content\"]\n",
    "    except:\n",
    "        print(f\"Error in {repo} \")            \n",
    "        time.sleep(3)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = []\n",
    "    for repo in all_patches_in_all_files_in_a_comit:      \n",
    "        all_responses_in_all_files_in_a_comit[repo] = []\n",
    "        for patch in all_patches_in_all_files_in_a_comit[repo]:\n",
    "            futures.append(executor.submit(categorize_patch, patch))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        for repo in all_patches_in_all_files_in_a_comit:\n",
    "            if future.result() is not None:\n",
    "                all_responses_in_all_files_in_a_comit[repo].append(future.result())\n",
    "\n",
    "\n",
    "print(all_responses_in_all_files_in_a_comit)\n",
    "with open(\"./pickles/GPT3_5_respons2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_responses_in_all_files_in_a_comit, f)\n",
    "with open(\"./pickles/GPT3_5_respons2.pkl\", \"rb\") as f:\n",
    "    all_responses_in_all_files_in_a_comit = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/openmm/openmm/commit/926e7b9ac11a8614f310b59a2d786788771ccb5b': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/ginkgo-project/ginkgo/commit/154aafbd57e93e4ede30b1566d2bf03e7c1b096e': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/arrayfire/arrayfire/commit/d8d8c439c8d0a43c0f92b11fd06133be80754ab8': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/gromacs/gromacs/commit/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/gromacs/gromacs/commit/8aa14d11ff775055794360a655fe800deea298a8': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/lattice/quda/commit/0dd4f75396999b649c759946fe0b53e6cd12aae0': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"],\n",
       " 'https://github.com/arrayfire/arrayfire/commit/46c66b5658beb84f4897581b16ae235f173ad97c': ['Inefficient memory management.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient memory management.',\n",
       "  'Unintentional Programming logic error',\n",
       "  'Missing parallelism',\n",
       "  'Inefficient algorithm /data-structure and their implementation.',\n",
       "  'Missing parallelism.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficiency due to new compiler version.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture.',\n",
       "  'Missing parallelism.',\n",
       "  'Inefficient coding for target micro-architecture (unable to identify any specific performance issue from the given code snippet, but the code may not be optimized for the target microarchitecture).',\n",
       "  'Inefficient coding for target micro-architecture. (There is no direct evidence of this in the given code snippet, but this conclusion is based on the fact that the code patch has nothing to do with microarchitecture optimization or tuning.)',\n",
       "  'Missing parallelism',\n",
       "  'This code snippet does not contain any performance issues. It is simply declaring a constant array. Therefore, it does not fall into any of the categories mentioned above.',\n",
       "  'Missing parallelism',\n",
       "  \"I'm sorry, there doesn't appear to be a specific patch or code for me to analyze and categorize. Could you please provide me with a code snippet or specific patch for me to work with?\",\n",
       "  'Category: Missing parallelism. \\n\\nThe given patches mainly involve defining variables, creating arrays, and setting up the CUDA context. There is no explicit parallelization of the code. However, the mention of CUDAArray, CUDANonbondedUtilities suggests that there may be plans to parallelize the code using the CUDA platform.',\n",
       "  'Without having the code and any information regarding the performance of the original implementation, it is impossible to accurately categorize these patches. The code changes could potentially address any one of the listed performance categories or even multiple categories. A thorough analysis of the code changes and their impact on performance would be necessary to make a conclusive determination.',\n",
       "  \"Missing parallelism. \\n\\nThe given code block does not seem to contain any specific performance issues. However, I can see a call to the 'tuneLaunch' function on line 50, which suggests that the code is attempting to optimize performance. The 'tuneLaunch' function is used for kernel tuning, where different configurations and parameters are tested to find the optimal version of the kernel. The kernel is then launched with the best configuration and parameters. In other words, the code is trying to find the best configuration for the kernel to achieve the best performance.\"]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_responses_in_all_files_in_a_comit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9\n",
      "Inefficient memory management.\n"
     ]
    }
   ],
   "source": [
    "for i in all_responses_in_all_files_in_a_comit:\n",
    "    #print(f\"for the commit {i} the ais classification is : \")\n",
    "    for j in all_responses_in_all_files_in_a_comit[i]:\n",
    "        print(i)#print(f\"-\\t\\t{j}\")\n",
    "        print(j)\n",
    "        break \n",
    "    break\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Sub-Sub-Category</th>\n",
       "      <th>Sub-Sub-Sub-Category</th>\n",
       "      <th>Sub-Sub-Sub-sub-Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link to commit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/28a9cb150ae9b11f9bb37d972be990d87b05cbcf</th>\n",
       "      <td>Inefficient coding for target micro-architecure</td>\n",
       "      <td>Memory/Data locality</td>\n",
       "      <td>Intra-thread data locality</td>\n",
       "      <td>cache locality</td>\n",
       "      <td>Inefficient data-structure (Use of non-contigu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/b0379f54bdff8236dee3a429b235167700ba23c0</th>\n",
       "      <td>Inefficient coding for target micro-architecure</td>\n",
       "      <td>Memory/Data locality</td>\n",
       "      <td>Intra-thread data locality</td>\n",
       "      <td>cache locality</td>\n",
       "      <td>Inefficient data-structure (Use of non-contigu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/mlpack/mlpack/commit/723dea88435686b72359793ace767d0b409635af</th>\n",
       "      <td>Inefficient coding for target micro-architecure</td>\n",
       "      <td>Memory/Data locality</td>\n",
       "      <td>Intra-thread data locality</td>\n",
       "      <td>cache locality</td>\n",
       "      <td>Inefficient data-structure (Use of non-contigu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/8855eb54c305ffeaec32cb6bc49bfb0a2e465cc2</th>\n",
       "      <td>Inefficient coding for target micro-architecure</td>\n",
       "      <td>Memory/Data locality</td>\n",
       "      <td>Intra-thread data locality</td>\n",
       "      <td>cache locality</td>\n",
       "      <td>Inefficient data-structure (Use of non-contigu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/lammps/lammps/commit/6c5edf6c709ef1fc9c914ec8049fa41a7fb3a49a</th>\n",
       "      <td>Inefficient coding for target micro-architecure</td>\n",
       "      <td>Memory/Data locality</td>\n",
       "      <td>Intra-thread data locality</td>\n",
       "      <td>cache locality</td>\n",
       "      <td>avoid memory referenced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/lattice/quda/commit/2ae74fd9959ebcaebb961af1717ac22093f05161</th>\n",
       "      <td>Inefficiency due to new compiler version</td>\n",
       "      <td>boundary condition check</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Inefficiency due to new compiler version</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Category  \\\n",
       "Link to commit                                                                                        \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...  Inefficient coding for target micro-architecure   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...  Inefficient coding for target micro-architecure   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...  Inefficient coding for target micro-architecure   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...  Inefficient coding for target micro-architecure   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...  Inefficient coding for target micro-architecure   \n",
       "...                                                                                             ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...         Inefficiency due to new compiler version   \n",
       "NaN                                                        Inefficiency due to new compiler version   \n",
       "NaN                                                                                             NaN   \n",
       "NaN                                                                                             NaN   \n",
       "NaN                                                                                             NaN   \n",
       "\n",
       "                                                                Sub-Category  \\\n",
       "Link to commit                                                                 \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...      Memory/Data locality   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...      Memory/Data locality   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...      Memory/Data locality   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...      Memory/Data locality   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...      Memory/Data locality   \n",
       "...                                                                      ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...  boundary condition check   \n",
       "NaN                                                                      NaN   \n",
       "NaN                                                                      NaN   \n",
       "NaN                                                                      NaN   \n",
       "NaN                                                                      NaN   \n",
       "\n",
       "                                                              Sub-Sub-Category  \\\n",
       "Link to commit                                                                   \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...  Intra-thread data locality   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...  Intra-thread data locality   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...  Intra-thread data locality   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...  Intra-thread data locality   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...  Intra-thread data locality   \n",
       "...                                                                        ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                         NaN   \n",
       "NaN                                                                        NaN   \n",
       "NaN                                                                        NaN   \n",
       "NaN                                                                        NaN   \n",
       "NaN                                                                        NaN   \n",
       "\n",
       "                                                   Sub-Sub-Sub-Category  \\\n",
       "Link to commit                                                            \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...       cache locality   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...       cache locality   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...       cache locality   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...       cache locality   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...       cache locality   \n",
       "...                                                                 ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                  NaN   \n",
       "NaN                                                                 NaN   \n",
       "NaN                                                                 NaN   \n",
       "NaN                                                                 NaN   \n",
       "NaN                                                                 NaN   \n",
       "\n",
       "                                                                             Sub-Sub-Sub-sub-Category  \n",
       "Link to commit                                                                                         \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...  Inefficient data-structure (Use of non-contigu...  \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...  Inefficient data-structure (Use of non-contigu...  \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...  Inefficient data-structure (Use of non-contigu...  \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...  Inefficient data-structure (Use of non-contigu...  \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                            avoid memory referenced  \n",
       "...                                                                                               ...  \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                                NaN  \n",
       "NaN                                                                                               NaN  \n",
       "NaN                                                                                               NaN  \n",
       "NaN                                                                                               NaN  \n",
       "NaN                                                                                               NaN  \n",
       "\n",
       "[190 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv from data/hashable.csv\n",
    "rq1_look_up = pd.read_csv('Data/other/hashable.csv')\n",
    "rq1_look_up = rq1_look_up [ [\"Category\",\"Sub-Category\",\"Sub-Sub-Category\",\"Sub-Sub-Sub-Category\",\"Sub-Sub-Sub-sub-Category\",\"Link to commit\" ]]\n",
    "\n",
    "rq1_look_up.set_index('Link to commit', inplace=True)\n",
    "rq1_look_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Sub-Category', 'Sub-Sub-Category', 'Sub-Sub-Sub-Category',\n",
       "       'Sub-Sub-Sub-sub-Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rq1_look_up.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a recursive function to create a nested dictionary\n",
    "def create_nested_dict(df):\n",
    "    if len(df.columns) == 1:\n",
    "        return df[df.columns[0]].tolist()\n",
    "    else:\n",
    "        return df.groupby(df.columns[0]).apply(lambda x: create_nested_dict(x.iloc[:, 1:])).to_dict()\n",
    "\n",
    "# Use the function on the DataFrame\n",
    "nested_dict_rq1 = create_nested_dict(rq1_look_up)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Memory/Data locality', 'Micro-architectural inefficiency'])\n"
     ]
    }
   ],
   "source": [
    "print(nested_dict_rq1[\"Inefficient coding for target micro-architecure\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/O inefficiency</th>\n",
       "      <th>Inefficiency due to new compiler version</th>\n",
       "      <th>Inefficient Concurrency control and synchronization</th>\n",
       "      <th>Inefficient algorithm /data-structure and their implementation</th>\n",
       "      <th>Inefficient coding for target micro-architecure</th>\n",
       "      <th>Inefficient memory management</th>\n",
       "      <th>Missing parallelism</th>\n",
       "      <th>Parallelization overhead/inefficiency</th>\n",
       "      <th>Unintentional Programming logic error</th>\n",
       "      <th>Unnecessary process communiction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link to commit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/28a9cb150ae9b11f9bb37d972be990d87b05cbcf</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/b0379f54bdff8236dee3a429b235167700ba23c0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/mlpack/mlpack/commit/723dea88435686b72359793ace767d0b409635af</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/CGAL/cgal/commit/8855eb54c305ffeaec32cb6bc49bfb0a2e465cc2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/lammps/lammps/commit/6c5edf6c709ef1fc9c914ec8049fa41a7fb3a49a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/lattice/quda/commit/2ae74fd9959ebcaebb961af1717ac22093f05161</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    I/O inefficiency  \\\n",
       "Link to commit                                                         \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                 0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                 0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                 0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                 0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                 0   \n",
       "...                                                              ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                 0   \n",
       "NaN                                                                0   \n",
       "NaN                                                                0   \n",
       "NaN                                                                0   \n",
       "NaN                                                                0   \n",
       "\n",
       "                                                    Inefficiency due to new compiler version  \\\n",
       "Link to commit                                                                                 \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                         0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                         0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                         0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                         0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                         0   \n",
       "...                                                                                      ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                         1   \n",
       "NaN                                                                                        1   \n",
       "NaN                                                                                        0   \n",
       "NaN                                                                                        0   \n",
       "NaN                                                                                        0   \n",
       "\n",
       "                                                    Inefficient Concurrency control and synchronization  \\\n",
       "Link to commit                                                                                            \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                                  0     \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                                  0     \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                                  0     \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                                  0     \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                                  0     \n",
       "...                                                                                               ...     \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                                  0     \n",
       "NaN                                                                                                 0     \n",
       "NaN                                                                                                 0     \n",
       "NaN                                                                                                 0     \n",
       "NaN                                                                                                 0     \n",
       "\n",
       "                                                    Inefficient algorithm /data-structure and their implementation  \\\n",
       "Link to commit                                                                                                       \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                                  0                \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                                  0                \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                                  0                \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                                  0                \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                                  0                \n",
       "...                                                                                               ...                \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                                  0                \n",
       "NaN                                                                                                 0                \n",
       "NaN                                                                                                 0                \n",
       "NaN                                                                                                 0                \n",
       "NaN                                                                                                 0                \n",
       "\n",
       "                                                    Inefficient coding for target micro-architecure  \\\n",
       "Link to commit                                                                                        \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                                1   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                                1   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                                1   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                                1   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                                1   \n",
       "...                                                                                             ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                                0   \n",
       "NaN                                                                                               0   \n",
       "NaN                                                                                               0   \n",
       "NaN                                                                                               0   \n",
       "NaN                                                                                               0   \n",
       "\n",
       "                                                    Inefficient memory management  \\\n",
       "Link to commit                                                                      \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                              0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                              0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                              0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                              0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                              0   \n",
       "...                                                                           ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                              0   \n",
       "NaN                                                                             0   \n",
       "NaN                                                                             0   \n",
       "NaN                                                                             0   \n",
       "NaN                                                                             0   \n",
       "\n",
       "                                                    Missing parallelism  \\\n",
       "Link to commit                                                            \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                    0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                    0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                    0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                    0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                    0   \n",
       "...                                                                 ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                    0   \n",
       "NaN                                                                   0   \n",
       "NaN                                                                   0   \n",
       "NaN                                                                   0   \n",
       "NaN                                                                   0   \n",
       "\n",
       "                                                    Parallelization overhead/inefficiency  \\\n",
       "Link to commit                                                                              \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                      0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                      0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                      0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                      0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                      0   \n",
       "...                                                                                   ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                      0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "\n",
       "                                                    Unintentional Programming logic error  \\\n",
       "Link to commit                                                                              \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                      0   \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                      0   \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                      0   \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                      0   \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                      0   \n",
       "...                                                                                   ...   \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                      0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "NaN                                                                                     0   \n",
       "\n",
       "                                                    Unnecessary process communiction  \n",
       "Link to commit                                                                        \n",
       "https://github.com/CGAL/cgal/commit/28a9cb150ae...                                 0  \n",
       "https://github.com/CGAL/cgal/commit/b0379f54bdf...                                 0  \n",
       "https://github.com/mlpack/mlpack/commit/723dea8...                                 0  \n",
       "https://github.com/CGAL/cgal/commit/8855eb54c30...                                 0  \n",
       "https://github.com/lammps/lammps/commit/6c5edf6...                                 0  \n",
       "...                                                                              ...  \n",
       "https://github.com/lattice/quda/commit/2ae74fd9...                                 0  \n",
       "NaN                                                                                0  \n",
       "NaN                                                                                0  \n",
       "NaN                                                                                0  \n",
       "NaN                                                                                0  \n",
       "\n",
       "[190 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RQ1_CAT_one_hot_df = pd.get_dummies(rq1_look_up['Category'])\n",
    "RQ1_CAT_one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses_pred_string_dict = {}  \n",
    "for i in all_responses_in_all_files_in_a_comit:\n",
    "    this_repos_pred_string = \"\"\n",
    "    for j in all_responses_in_all_files_in_a_comit[i]:\n",
    "        this_repos_pred_string+=j\n",
    "    all_responses_pred_string_dict[i] = this_repos_pred_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inefficient coding for target micro-architecure</th>\n",
       "      <th>Missing parallelism</th>\n",
       "      <th>Parallelization overhead/inefficiency</th>\n",
       "      <th>Inefficient Concurrency control and synchronization</th>\n",
       "      <th>Unnecessary process communication</th>\n",
       "      <th>Inefficient algorithm /data-structure and their implementation</th>\n",
       "      <th>Inefficient memory management</th>\n",
       "      <th>I/O inefficiency</th>\n",
       "      <th>Unintentional Programming logic error</th>\n",
       "      <th>Inefficiency due to new compiler version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/lattice/quda/commit/b7857af47ff2e8e8162a250a4adefba55680b1c9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/openmm/openmm/commit/926e7b9ac11a8614f310b59a2d786788771ccb5b</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/ginkgo-project/ginkgo/commit/154aafbd57e93e4ede30b1566d2bf03e7c1b096e</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/arrayfire/arrayfire/commit/d8d8c439c8d0a43c0f92b11fd06133be80754ab8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/arrayfire/arrayfire/commit/113cb18160a31d8ee04d11969bc57ff1628bda50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/gromacs/gromacs/commit/3e52c82b8ffa11bfa318396eb8e86cbd0f9b7446</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/gromacs/gromacs/commit/8aa14d11ff775055794360a655fe800deea298a8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/lattice/quda/commit/0dd4f75396999b649c759946fe0b53e6cd12aae0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/arrayfire/arrayfire/commit/46c66b5658beb84f4897581b16ae235f173ad97c</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Inefficient coding for target micro-architecure  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                                0   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                                0   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                                0   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                                0   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                                0   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                                0   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                                0   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                                0   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                                0   \n",
       "\n",
       "                                                    Missing parallelism  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                    1   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                    1   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                    1   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                    1   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                    1   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                    1   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                    1   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                    1   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                    1   \n",
       "\n",
       "                                                    Parallelization overhead/inefficiency  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                      0   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                      0   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                      0   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                      0   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                      0   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                      0   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                      0   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                      0   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                      0   \n",
       "\n",
       "                                                    Inefficient Concurrency control and synchronization  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                                  0     \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                                  0     \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                                  0     \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                                  0     \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                                  0     \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                                  0     \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                                  0     \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                                  0     \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                                  0     \n",
       "\n",
       "                                                    Unnecessary process communication  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                  0   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                  0   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                  0   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                  0   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                  0   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                  0   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                  0   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                  0   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                  0   \n",
       "\n",
       "                                                    Inefficient algorithm /data-structure and their implementation  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                                  1                \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                                  1                \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                                  1                \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                                  1                \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                                  1                \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                                  1                \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                                  1                \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                                  1                \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                                  1                \n",
       "\n",
       "                                                    Inefficient memory management  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                              1   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                              1   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                              1   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                              1   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                              1   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                              1   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                              1   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                              1   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                              1   \n",
       "\n",
       "                                                    I/O inefficiency  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                 0   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                 0   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                 0   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                 0   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                 0   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                 0   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                 0   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                 0   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                 0   \n",
       "\n",
       "                                                    Unintentional Programming logic error  \\\n",
       "https://github.com/lattice/quda/commit/b7857af4...                                      1   \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                      1   \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                      1   \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                      1   \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                      1   \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                      1   \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                      1   \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                      1   \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                      1   \n",
       "\n",
       "                                                    Inefficiency due to new compiler version  \n",
       "https://github.com/lattice/quda/commit/b7857af4...                                         1  \n",
       "https://github.com/openmm/openmm/commit/926e7b9...                                         1  \n",
       "https://github.com/ginkgo-project/ginkgo/commit...                                         1  \n",
       "https://github.com/arrayfire/arrayfire/commit/d...                                         1  \n",
       "https://github.com/arrayfire/arrayfire/commit/1...                                         1  \n",
       "https://github.com/gromacs/gromacs/commit/3e52c...                                         1  \n",
       "https://github.com/gromacs/gromacs/commit/8aa14...                                         1  \n",
       "https://github.com/lattice/quda/commit/0dd4f753...                                         1  \n",
       "https://github.com/arrayfire/arrayfire/commit/4...                                         1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in all_responses_pred_string_dict:    \n",
    "    for cat in RQ1_dict: \n",
    "        if cat.lower() in all_responses_pred_string_dict[i].lower():\n",
    "            pass#print(f\"{cat}\")\n",
    "\n",
    "\n",
    "# Create a list to hold the individual series\n",
    "series_list = []\n",
    "keys_list = []  # to store the keys\n",
    "\n",
    "for key, value in all_responses_pred_string_dict.items():\n",
    "    row_dict = {}\n",
    "    for cat in RQ1_dict:\n",
    "        if cat.lower() in value.lower():\n",
    "            row_dict[cat] = 1  # Mark with 1 if category is in the response\n",
    "        else:\n",
    "            row_dict[cat] = 0  # Mark with 0 if category is not in the response\n",
    "    # Convert the dict to a Series and add it to the list\n",
    "    series_list.append(pd.Series(row_dict))\n",
    "    keys_list.append(key)  # add the key to the list\n",
    "\n",
    "# Concatenate all the series into a DataFrame\n",
    "cat_pred_df = pd.concat(series_list, axis=1).T\n",
    "\n",
    "# Set column names as categories in RQ1_dict\n",
    "cat_pred_df.columns = RQ1_dict\n",
    "\n",
    "# Add the keys as a new column (or as index if you prefer)\n",
    "cat_pred_df.index = keys_list\n",
    "\n",
    "cat_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Inefficient coding for target micro-architecure',\n",
      "       'Missing parallelism', 'Parallelization overhead/inefficiency',\n",
      "       'Inefficient Concurrency control and synchronization',\n",
      "       'Unnecessary process communication',\n",
      "       'Inefficient algorithm /data-structure and their implementation',\n",
      "       'Inefficient memory management', 'I/O inefficiency',\n",
      "       'Unintentional Programming logic error',\n",
      "       'Inefficiency due to new compiler version'],\n",
      "      dtype='object')\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print ( cat_pred_df.columns )\n",
    "print ( len( cat_pred_df.columns ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['I/O inefficiency', 'Inefficiency due to new compiler version',\n",
      "       'Inefficient Concurrency control and synchronization',\n",
      "       'Inefficient algorithm /data-structure and their implementation',\n",
      "       'Inefficient coding for target micro-architecure',\n",
      "       'Inefficient memory management', 'Missing parallelism',\n",
      "       'Parallelization overhead/inefficiency',\n",
      "       'Unintentional Programming logic error',\n",
      "       'Unnecessary process communiction'],\n",
      "      dtype='object')\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print( RQ1_CAT_one_hot_df.columns )\n",
    "print( len( RQ1_CAT_one_hot_df.columns ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RQ1_CAT_one_hot_df = RQ1_CAT_one_hot_df.rename(columns={'Unnecessary process communiction': 'Unnecessary process communication'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is : Inefficient coding for target micro-architecure, Missing parallelism, Parallelization overhead/inefficiency, Inefficient Concurrency control and synchronization, Unnecessary process communication, Inefficient algorithm /data-structure and their implementation, Inefficient memory management, I/O inefficiency, Unintentional Programming logic error, Inefficiency due to new compiler version, \n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Get the common indexes\n",
    "common_index = RQ1_CAT_one_hot_df.index.intersection(cat_pred_df.index)\n",
    "\n",
    "# Subset the DataFrames using the common index\n",
    "RQ1_CAT_one_hot_df_common = RQ1_CAT_one_hot_df.loc[common_index]\n",
    "cat_pred_df_common = cat_pred_df.loc[common_index]\n",
    "\n",
    "# Make sure both DataFrames are aligned and have the same columns\n",
    "RQ1_CAT_one_hot_df_common = RQ1_CAT_one_hot_df_common[cat_pred_df_common.columns]\n",
    "\n",
    "# Define the rules for the new DataFrame\n",
    "conditions = [\n",
    "    (RQ1_CAT_one_hot_df_common == 1) & (cat_pred_df_common == 1),  # Both are 1\n",
    "    (RQ1_CAT_one_hot_df_common == 0) & (cat_pred_df_common == 1),  # Pred is 1, RQ1_CAT_one_hot_df is 0\n",
    "    (RQ1_CAT_one_hot_df_common == 1) & (cat_pred_df_common == 0),  # Pred is 0, RQ1_CAT_one_hot_df is 1\n",
    "    (RQ1_CAT_one_hot_df_common == 0) & (cat_pred_df_common == 0)  # Both are 0\n",
    "]\n",
    "\n",
    "# Define the corresponding values (you can use any unique values)\n",
    "values = [3, 2, 1, 0]\n",
    "\n",
    "# Create the new DataFrame using np.select to map conditions to values\n",
    "df_new = pd.DataFrame(np.select(conditions, values, default=np.nan), \n",
    "                      index=RQ1_CAT_one_hot_df_common.index, columns=RQ1_CAT_one_hot_df_common.columns)\n",
    "\n",
    "# Define the color map\n",
    "cmap = ListedColormap(['black', 'blue', 'red', 'green'])\n",
    "\n",
    "# Plot the heatmap\n",
    "\n",
    "plt.figure(figsize=(4, 10))\n",
    "sns.heatmap(df_new, cmap=cmap, cbar=False)\n",
    "\n",
    "# Remove y-axis labels\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "tmp_str = \"\"\n",
    "for i in df_new.columns:\n",
    "    tmp_str += i + \", \"\n",
    "print(\"is :\" ,tmp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both predict 0 36\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1533\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:1542\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\canko\\Documents\\cs406\\proj\\final.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#print(condition_counts)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#3 for both are 1,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#2 for Pred is 1, RQ1_CAT_one_hot_df is 0,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#1 for Pred is 0, RQ1_CAT_one_hot_df is 1,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#0 for both are 0.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth predict 0 \u001b[39m\u001b[39m{\u001b[39;00mcondition_counts[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth predicts 1 \u001b[39m\u001b[39m{\u001b[39;00mcondition_counts[\u001b[39m3\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel predicts 0 ground truth is 1 \u001b[39m\u001b[39m{\u001b[39;00mcondition_counts[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/canko/Documents/cs406/proj/final.ipynb#Y154sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel predicts 1 ground truth is 0 \u001b[39m\u001b[39m{\u001b[39;00mcondition_counts[\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\canko\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "condition_counts = df_new.stack().value_counts()\n",
    "\n",
    "#print(condition_counts)\n",
    "#3 for both are 1,\n",
    "#2 for Pred is 1, RQ1_CAT_one_hot_df is 0,\n",
    "#1 for Pred is 0, RQ1_CAT_one_hot_df is 1,\n",
    "#0 for both are 0.\n",
    "print(f\"both predict 0 {condition_counts[0]}\")\n",
    "print(f\"both predicts 1 {condition_counts[3]}\")\n",
    "print(f\"model predicts 0 ground truth is 1 {condition_counts[1]}\")\n",
    "print(f\"model predicts 1 ground truth is 0 {condition_counts[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = condition_counts[3]\n",
    "TN = condition_counts[0]\n",
    "FP = condition_counts[2]\n",
    "FN = condition_counts[1]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "false_negative_rate = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over the evaluation metrics for our model:\n",
    "\n",
    "Accuracy - Our model correctly predicted the outcome 83.06% of the time. This might seem impressive at first glance. However, accuracy can sometimes give us a distorted picture if our data is skewed or imbalanced, meaning one class has far more instances than the other.\n",
    "\n",
    "Precision - This measure tells us how often our model is right when it predicts the positive class. At 13.14%, our model's precision is relatively low, indicating that our positive predictions are incorrect a significant amount of the time.\n",
    "\n",
    "Recall - This metric gives us the percentage of actual positive cases our model managed to capture through its predictions. Here, our model detected only 12.37% of all positive cases. This low recall suggests that our model is missing a large number of positive cases—it's not finding all the instances it should be finding.\n",
    "\n",
    "F1 Score - The F1 Score is a blend of precision and recall, giving us a single measure that tries to balance the two. Ideally, we want an F1 score close to 1. Our model's F1 score is just 12.74%, which is rather low, indicating our model's performance is not balanced when it comes to precision and recall.\n",
    "\n",
    "False Negative Rate - This measure tells us how often our model wrongly predicted a positive case as negative. With a high rate of 87.63%, our model is frequently predicting positive instances as negative—this is a substantial issue.\n",
    "\n",
    "In summary, while our model shows a reasonable accuracy rate, other metrics suggest substantial areas for improvement. The model often fails to identify positive instances and frequently mislabels them—a problem indicated by the low precision, low recall, and high false negative rate. Future steps could include exploring different models, refining feature engineering, or balancing our dataset if it is found to be skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub_catogary_responses_in_all_files_in_a_comit = {}\n",
    "with open(\"./pickles/GPT3_5_respons2_sub_cat_pred.pkl\", \"rb\") as f:\n",
    "    all_sub_catogary_responses_in_all_files_in_a_comit = pickle.load(f)\n",
    "\n",
    "rq1_look_copy = rq1_look_up.copy()\n",
    "def ask_the_model(category, index):    \n",
    "    '''tmp_str = \"\"\n",
    "    for i in nested_dict_rq1[category]:\n",
    "        tmp_str+=i+\", \"\n",
    "    system_promt_for_sub_catogary = f\"As a software high performance engineering assistant with exceptional intelligence, your task is to analyze a given piece of code and identify any performance issues. Specifically it is known that this patch solves a problem about {category}, you are expected to classify any performance problem and the given solution you detect into only  single one of the following categories: {tmp_str}\"\n",
    "\n",
    "    #print(system_promt_for_sub_catogary)\n",
    "    all_sub_catogary_responses_in_all_files_in_a_comit[index]=\"\"\n",
    "    for patch  in all_patches_in_all_files_in_a_comit[index]:\n",
    "        #print(patch)\n",
    "        try: \n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_promt_for_sub_catogary },\n",
    "                    {\"role\": \"user\", \"content\": f\"If you think this solves a {category} problem please categorize the following patches into single one of the listed categories ? {patch}  ?  \"} ,       \n",
    "                    ],  \n",
    "            )            \n",
    "            all_sub_catogary_responses_in_all_files_in_a_comit[index]+= \" \" +response['choices'][0]['message'][\"content\"]\n",
    "             # to avoid openai api rate limit\n",
    "        except:\n",
    "            print(f\"Error in {repo} \")    \n",
    "            all_sub_catogary_responses_in_all_files_in_a_comit[index]+= \" \" \n",
    "        \n",
    "            time.sleep(3)\n",
    "    #print(all_responses_in_all_files_in_a_comit)\n",
    "    '''\n",
    "    if index in all_sub_catogary_responses_in_all_files_in_a_comit:\n",
    "        return all_sub_catogary_responses_in_all_files_in_a_comit[index]\n",
    "    else:\n",
    "        return \"\"\n",
    "rq1_look_copy['sub_catogary_predstring'] = rq1_look_copy.apply(lambda row: ask_the_model(row['Category'], row.name), axis=1)\n",
    "#rq1_look_copy\n",
    "#with open(\"./pickles/GPT3_5_respons2_sub_cat_pred.pkl\", \"wb\") as f:\n",
    "    #pickle.dump(all_sub_catogary_responses_in_all_files_in_a_comit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rq1_look_copy[\"sub_catogary_predstring\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_cats=[]\n",
    "for i in nested_dict_rq1.keys():\n",
    "    Sub_cats.extend(nested_dict_rq1[i])\n",
    "Sub_cats\n",
    "Sub_cats = list(set(Sub_cats))\n",
    "len(Sub_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RQ1_sub_CAT_one_hot_df = pd.get_dummies(rq1_look_up['Sub-Category'])\n",
    "len(RQ1_sub_CAT_one_hot_df.columns)\n",
    "RQ1_sub_CAT_one_hot_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sub_cat_df = pd.DataFrame(index=rq1_look_copy.index)\n",
    "\n",
    "for sub_cat in Sub_cats:\n",
    "    pred_sub_cat_df[sub_cat] = rq1_look_copy['sub_catogary_predstring'].apply(lambda x: int(sub_cat in x))\n",
    "\n",
    "pred_sub_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Get the common indexes\n",
    "common_index = RQ1_sub_CAT_one_hot_df.index.intersection(pred_sub_cat_df.index)\n",
    "\n",
    "# Subset the DataFrames using the common index\n",
    "RQ1_sub_CAT_one_hot_df_common = RQ1_sub_CAT_one_hot_df.loc[common_index]\n",
    "pred_sub_cat_df_common = pred_sub_cat_df.loc[common_index]\n",
    "\n",
    "# Make sure both DataFrames are aligned and have the same columns\n",
    "RQ1_sub_CAT_one_hot_df_common = RQ1_sub_CAT_one_hot_df_common[pred_sub_cat_df_common.columns]\n",
    "\n",
    "# Define the rules for the new DataFrame\n",
    "conditions = [\n",
    "    (RQ1_sub_CAT_one_hot_df_common == 1) & (pred_sub_cat_df_common == 1),  # Both are 1\n",
    "    (RQ1_sub_CAT_one_hot_df_common == 0) & (pred_sub_cat_df_common == 1),  # Pred is 1, RQ1_sub_CAT_one_hot_df is 0\n",
    "    (RQ1_sub_CAT_one_hot_df_common == 1) & (pred_sub_cat_df_common == 0),  # Pred is 0, RQ1_sub_CAT_one_hot_df is 1\n",
    "    (RQ1_sub_CAT_one_hot_df_common == 0) & (pred_sub_cat_df_common == 0)  # Both are 0\n",
    "]\n",
    "\n",
    "# Define the corresponding values (you can use any unique values)\n",
    "values = [3, 2, 1, 0]\n",
    "\n",
    "# Create the new DataFrame using np.select to map conditions to values\n",
    "df_new = pd.DataFrame(np.select(conditions, values, default=np.nan), \n",
    "                      index=RQ1_sub_CAT_one_hot_df_common.index, columns=RQ1_sub_CAT_one_hot_df_common.columns)\n",
    "\n",
    "# Define the color map\n",
    "cmap = ListedColormap(['black', 'blue', 'red', 'green'])\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_new, cmap=cmap, cbar=False)\n",
    "\n",
    "# Remove y-axis labels\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "tmp_str = \"\"\n",
    "for i in df_new.columns:\n",
    "    tmp_str += i + \", \"\n",
    "print(\"is :\" ,tmp_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_counts = df_new.stack().value_counts()\n",
    "\n",
    "#print(condition_counts)\n",
    "#3 for both are 1,\n",
    "#2 for Pred is 1, RQ1_CAT_one_hot_df is 0,\n",
    "#1 for Pred is 0, RQ1_CAT_one_hot_df is 1,\n",
    "#0 for both are 0.\n",
    "print(f\"both predict 0 {condition_counts[0]}\")\n",
    "print(f\"both predicts 1 {condition_counts[3]}\")\n",
    "print(f\"model predicts 0 ground truth is 1 {condition_counts[1]}\")\n",
    "print(f\"model predicts 1 ground truth is 0 {condition_counts[2]}\")\n",
    "TP = condition_counts[3]\n",
    "TN = condition_counts[0]\n",
    "FP = condition_counts[2]\n",
    "FN = condition_counts[1]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "false_negative_rate = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance evaluation metrics of the model deliver unique insights:\n",
    "\n",
    "Accuracy (95.43%): The model's accuracy, which represents the proportion of correct predictions (both true positives and true negatives) over all predictions, is 95.43%. This suggests that the model can predict correctly in 95.43% of the cases. However, this metric can often be misleading if the classes in the dataset are unbalanced. Even though the accuracy seems impressive, caution is advised in such scenarios.\n",
    "\n",
    "Precision (31.46%): Precision, defined as the proportion of true positives to all positive predictions (true positives and false positives), stands at 31.46%. This relatively low score implies that the model only correctly predicts a positive class 31.46% of the time. The model thus demonstrates a significant rate of false positives, inaccurately identifying negative instances as positive.\n",
    "\n",
    "Recall (30.11%): The model's recall, also known as sensitivity, measures the proportion of true positives to all actual positive instances (true positives and false negatives). A recall rate of 30.11% signifies that the model successfully identifies only 30.11% of all positive instances. This low recall score reveals the model's inability to detect a substantial number of positive instances.\n",
    "\n",
    "F1 Score (30.77%): The F1 Score is the harmonic mean of precision and recall, providing a balanced measure of these two metrics. An F1 Score closer to 1 is ideal, as it signifies well-balanced precision and recall. The current model's F1 score, being quite low, suggests a lack of harmony between the model's precision and recall.\n",
    "\n",
    "False Negative Rate (69.89%): The False Negative Rate (FNR) represents the proportion of actual positive instances incorrectly classified as negative by the model. A high FNR is typically undesirable because it indicates frequent misclassifications of positive instances. In this case, the high FNR suggests that the model often fails to accurately identify positive instances.\n",
    "\n",
    "In summary, despite a high accuracy, the model's performance seems inadequate, particularly in its correct identification of positive instances. Evidenced by the high number of false negatives (missed positives) and a considerable number of false positives (low precision), the model requires improvement. Potential improvement strategies could include trying different algorithms, tuning the model's hyperparameters, implementing feature engineering techniques, rebalancing the dataset if it is imbalanced, or acquiring more relevant data. Importantly, the chosen metrics for performance evaluation should align with the specific requirements and context of the task. Depending on the problem, a higher False Negative Rate might sometimes be more acceptable than a higher False Positive Rate, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
